{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, concat\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu.idle.pct</th>\n",
       "      <th>system.cpu.iowait.pct</th>\n",
       "      <th>system.cpu.softirq.pct</th>\n",
       "      <th>system.cpu.system.pct</th>\n",
       "      <th>system.cpu.total.pct</th>\n",
       "      <th>system.cpu.user.pct</th>\n",
       "      <th>system.diskio_sda.iostat.await</th>\n",
       "      <th>system.diskio_sda.iostat.busy</th>\n",
       "      <th>system.diskio_sda.iostat.queue.avg_size</th>\n",
       "      <th>system.diskio_sda.iostat.read.request.merges_per_sec</th>\n",
       "      <th>...</th>\n",
       "      <th>jolokia.metrics.threading.thread_count</th>\n",
       "      <th>system.load.1</th>\n",
       "      <th>system.load.15</th>\n",
       "      <th>system.load.5</th>\n",
       "      <th>system.load.norm.1</th>\n",
       "      <th>system.load.norm.15</th>\n",
       "      <th>system.load.norm.5</th>\n",
       "      <th>system.memory.actual.used.pct</th>\n",
       "      <th>system.memory.swap.used.pct</th>\n",
       "      <th>system.memory.used.pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5818</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.2338</td>\n",
       "      <td>0.698</td>\n",
       "      <td>12.601</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>995</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.6904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5080</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.4920</td>\n",
       "      <td>0.2661</td>\n",
       "      <td>0.572</td>\n",
       "      <td>11.104</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>995</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5337</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.4663</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.572</td>\n",
       "      <td>11.104</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>995</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.6904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.5742</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.4258</td>\n",
       "      <td>0.2637</td>\n",
       "      <td>0.572</td>\n",
       "      <td>11.104</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>995</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5454</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.4546</td>\n",
       "      <td>0.2522</td>\n",
       "      <td>0.572</td>\n",
       "      <td>11.104</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>995</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   system.cpu.idle.pct  system.cpu.iowait.pct  system.cpu.softirq.pct  \\\n",
       "0               3.5818                 0.0474                  0.0312   \n",
       "1               3.5080                 0.0934                  0.0271   \n",
       "2               3.5337                 0.1136                  0.0291   \n",
       "3               3.5742                 0.0503                  0.0201   \n",
       "4               3.5454                 0.0705                  0.0268   \n",
       "\n",
       "   system.cpu.system.pct  system.cpu.total.pct  system.cpu.user.pct  \\\n",
       "0                 0.1058                0.4182               0.2338   \n",
       "1                 0.1054                0.4920               0.2661   \n",
       "2                 0.1025                0.4663               0.2211   \n",
       "3                 0.0916                0.4258               0.2637   \n",
       "4                 0.1051                0.4546               0.2522   \n",
       "\n",
       "   system.diskio_sda.iostat.await  system.diskio_sda.iostat.busy  \\\n",
       "0                           0.698                         12.601   \n",
       "1                           0.572                         11.104   \n",
       "2                           0.572                         11.104   \n",
       "3                           0.572                         11.104   \n",
       "4                           0.572                         11.104   \n",
       "\n",
       "   system.diskio_sda.iostat.queue.avg_size  \\\n",
       "0                                    0.165   \n",
       "1                                    0.137   \n",
       "2                                    0.137   \n",
       "3                                    0.137   \n",
       "4                                    0.137   \n",
       "\n",
       "   system.diskio_sda.iostat.read.request.merges_per_sec  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "2                                                0.0      \n",
       "3                                                0.0      \n",
       "4                                                0.0      \n",
       "\n",
       "            ...            jolokia.metrics.threading.thread_count  \\\n",
       "0           ...                                               995   \n",
       "1           ...                                               995   \n",
       "2           ...                                               995   \n",
       "3           ...                                               995   \n",
       "4           ...                                               995   \n",
       "\n",
       "   system.load.1  system.load.15  system.load.5  system.load.norm.1  \\\n",
       "0           0.68            0.97           1.00               0.170   \n",
       "1           0.58            0.96           0.97               0.145   \n",
       "2           0.65            0.96           0.97               0.163   \n",
       "3           0.68            0.95           0.95               0.170   \n",
       "4           0.68            0.95           0.95               0.170   \n",
       "\n",
       "   system.load.norm.15  system.load.norm.5  system.memory.actual.used.pct  \\\n",
       "0                0.243               0.250                         0.6904   \n",
       "1                0.240               0.243                         0.6903   \n",
       "2                0.240               0.243                         0.6904   \n",
       "3                0.238               0.238                         0.6903   \n",
       "4                0.238               0.238                         0.6905   \n",
       "\n",
       "   system.memory.swap.used.pct  system.memory.used.pct  \n",
       "0                          0.0                  0.9620  \n",
       "1                          0.0                  0.9626  \n",
       "2                          0.0                  0.9628  \n",
       "3                          0.0                  0.9635  \n",
       "4                          0.0                  0.9638  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = read_csv('with_timestamp.csv', header=0, index_col=0)\n",
    "dataset.drop([\"@timestamp\", \"anomaly\"], axis=1, inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Multiple Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_epoches = 200\n",
    "model_batch_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset.columns] = StandardScaler().fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting the dataset\n",
    "shifting only one minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_param = shift*(-6)\n",
    "dataset_shifted = dataset.shift(shift_param)\n",
    "dataset = dataset.iloc[:shift_param]\n",
    "dataset_shifted = dataset_shifted.iloc[:shift_param]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the dataset \n",
    "Ratio - 80 : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.shape[0] * 2 // 10\n",
    "    \n",
    "train_dataset = dataset.iloc[:-train]\n",
    "train_dataset_shifted = dataset_shifted.iloc[:-train]\n",
    "\n",
    "test_dataset = dataset.iloc[-train:]\n",
    "test_dataset_shifted = dataset_shifted.iloc[-train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39976, 39)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.values.reshape((train_dataset.shape[0], 1, train_dataset.shape[1]))\n",
    "test_dataset_shaped = test_dataset.values.reshape((test_dataset.shape[0], 1, test_dataset.shape[1]))\n",
    "print(train_dataset_shifted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set 1\n",
    "- system.cpu.iowait.pct'\n",
    "- system.diskio_sda.iostat.await'\n",
    "- system.diskio_sda.iostat.busy'\n",
    "- system.diskio_sda.iostat.queue.avg_size'\n",
    "- system.diskio_sda.iostat.read.request.merges_per_sec'\n",
    "- system.diskio_sda.iostat.read.request.per_sec'\n",
    "- system.diskio_sda.iostat.request.avg_size'\n",
    "- system.diskio_sda.iostat.service_time'\n",
    "- system.diskio_sda.iostat.write.request.merges_per_sec'\n",
    "- system.diskio_sda.iostat.write.request.per_sec'\n",
    "- system.diskio_sda2.iostat.await'\n",
    "- system.diskio_sda2.iostat.busy'\n",
    "- system.diskio_sda2.iostat.queue.avg_size'\n",
    "- system.diskio_sda2.iostat.read.request.merges_per_sec'\n",
    "- system.diskio_sda2.iostat.read.request.per_sec'\n",
    "- system.diskio_sda2.iostat.request.avg_size'\n",
    "- system.diskio_sda2.iostat.service_time'\n",
    "- system.diskio_sda2.iostat.write.request.merges_per_sec'\n",
    "- system.diskio_sda2.iostat.write.request.per_sec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_shifted_1 = train_dataset_shifted[[\n",
    "    'system.cpu.iowait.pct',\n",
    "    'system.diskio_sda.iostat.await',\n",
    "    'system.diskio_sda.iostat.busy',\n",
    "    'system.diskio_sda.iostat.queue.avg_size',\n",
    "    'system.diskio_sda.iostat.read.request.merges_per_sec',\n",
    "    'system.diskio_sda.iostat.read.request.per_sec',\n",
    "    'system.diskio_sda.iostat.request.avg_size',\n",
    "    'system.diskio_sda.iostat.service_time',\n",
    "    'system.diskio_sda.iostat.write.request.merges_per_sec',\n",
    "    'system.diskio_sda.iostat.write.request.per_sec',\n",
    "    'system.diskio_sda2.iostat.await',\n",
    "    'system.diskio_sda2.iostat.busy',\n",
    "    'system.diskio_sda2.iostat.queue.avg_size',\n",
    "    'system.diskio_sda2.iostat.read.request.merges_per_sec',\n",
    "    'system.diskio_sda2.iostat.read.request.per_sec',\n",
    "    'system.diskio_sda2.iostat.request.avg_size',\n",
    "    'system.diskio_sda2.iostat.service_time',\n",
    "    'system.diskio_sda2.iostat.write.request.merges_per_sec',\n",
    "    'system.diskio_sda2.iostat.write.request.per_sec']]\n",
    "train_dataset_shifted_1.head()\n",
    "\n",
    "test_dataset_shifted_1 = test_dataset_shifted[[\n",
    "    'system.cpu.iowait.pct',\n",
    "    'system.diskio_sda.iostat.await',\n",
    "    'system.diskio_sda.iostat.busy',\n",
    "    'system.diskio_sda.iostat.queue.avg_size',\n",
    "    'system.diskio_sda.iostat.read.request.merges_per_sec',\n",
    "    'system.diskio_sda.iostat.read.request.per_sec',\n",
    "    'system.diskio_sda.iostat.request.avg_size',\n",
    "    'system.diskio_sda.iostat.service_time',\n",
    "    'system.diskio_sda.iostat.write.request.merges_per_sec',\n",
    "    'system.diskio_sda.iostat.write.request.per_sec',\n",
    "    'system.diskio_sda2.iostat.await',\n",
    "    'system.diskio_sda2.iostat.busy',\n",
    "    'system.diskio_sda2.iostat.queue.avg_size',\n",
    "    'system.diskio_sda2.iostat.read.request.merges_per_sec',\n",
    "    'system.diskio_sda2.iostat.read.request.per_sec',\n",
    "    'system.diskio_sda2.iostat.request.avg_size',\n",
    "    'system.diskio_sda2.iostat.service_time',\n",
    "    'system.diskio_sda2.iostat.write.request.merges_per_sec',\n",
    "    'system.diskio_sda2.iostat.write.request.per_sec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 9s - loss: 0.7430\n",
      "Epoch 2/200\n",
      " - 5s - loss: 0.6886\n",
      "Epoch 3/200\n",
      " - 5s - loss: 0.6439\n",
      "Epoch 4/200\n",
      " - 6s - loss: 0.6063\n",
      "Epoch 5/200\n",
      " - 6s - loss: 0.5750\n",
      "Epoch 6/200\n",
      " - 5s - loss: 0.5486\n",
      "Epoch 7/200\n",
      " - 5s - loss: 0.5279\n",
      "Epoch 8/200\n",
      " - 5s - loss: 0.5088\n",
      "Epoch 9/200\n",
      " - 5s - loss: 0.4942\n",
      "Epoch 10/200\n",
      " - 6s - loss: 0.4825\n",
      "Epoch 11/200\n",
      " - 5s - loss: 0.4732\n",
      "Epoch 12/200\n",
      " - 6s - loss: 0.4686\n",
      "Epoch 13/200\n",
      " - 6s - loss: 0.4607\n",
      "Epoch 14/200\n",
      " - 7s - loss: 0.4562\n",
      "Epoch 15/200\n",
      " - 6s - loss: 0.4527\n",
      "Epoch 16/200\n",
      " - 5s - loss: 0.4497\n",
      "Epoch 17/200\n",
      " - 6s - loss: 0.4463\n",
      "Epoch 18/200\n",
      " - 6s - loss: 0.4449\n",
      "Epoch 19/200\n",
      " - 6s - loss: 0.4429\n",
      "Epoch 20/200\n",
      " - 6s - loss: 0.4428\n",
      "Epoch 21/200\n",
      " - 7s - loss: 0.4411\n",
      "Epoch 22/200\n",
      " - 6s - loss: 0.4413\n",
      "Epoch 23/200\n",
      " - 5s - loss: 0.4375\n",
      "Epoch 24/200\n",
      " - 6s - loss: 0.4353\n",
      "Epoch 25/200\n",
      " - 5s - loss: 0.4397\n",
      "Epoch 26/200\n",
      " - 5s - loss: 0.4338\n",
      "Epoch 27/200\n",
      " - 6s - loss: 0.4325\n",
      "Epoch 28/200\n",
      " - 6s - loss: 0.4282\n",
      "Epoch 29/200\n",
      " - 6s - loss: 0.4373\n",
      "Epoch 30/200\n",
      " - 6s - loss: 0.4240\n",
      "Epoch 31/200\n",
      " - 6s - loss: 0.4318\n",
      "Epoch 32/200\n",
      " - 6s - loss: 0.4233\n",
      "Epoch 33/200\n",
      " - 7s - loss: 0.4221\n",
      "Epoch 34/200\n",
      " - 7s - loss: 0.4245\n",
      "Epoch 35/200\n",
      " - 6s - loss: 0.4345\n",
      "Epoch 36/200\n",
      " - 6s - loss: 0.4294\n",
      "Epoch 37/200\n",
      " - 6s - loss: 0.4286\n",
      "Epoch 38/200\n",
      " - 6s - loss: 0.4279\n",
      "Epoch 39/200\n",
      " - 6s - loss: 0.4204\n",
      "Epoch 40/200\n",
      " - 6s - loss: 0.4227\n",
      "Epoch 41/200\n",
      " - 6s - loss: 0.4243\n",
      "Epoch 42/200\n",
      " - 6s - loss: 0.4148\n",
      "Epoch 43/200\n",
      " - 6s - loss: 0.4165\n",
      "Epoch 44/200\n",
      " - 6s - loss: 0.4204\n",
      "Epoch 45/200\n",
      " - 5s - loss: 0.4246\n",
      "Epoch 46/200\n",
      " - 5s - loss: 0.4119\n",
      "Epoch 47/200\n",
      " - 6s - loss: 0.4122\n",
      "Epoch 48/200\n",
      " - 6s - loss: 0.4167\n",
      "Epoch 49/200\n",
      " - 6s - loss: 0.4246\n",
      "Epoch 50/200\n",
      " - 5s - loss: 0.4236\n",
      "Epoch 51/200\n",
      " - 5s - loss: 0.4137\n",
      "Epoch 52/200\n",
      " - 5s - loss: 0.4177\n",
      "Epoch 53/200\n",
      " - 5s - loss: 0.4130\n",
      "Epoch 54/200\n",
      " - 5s - loss: 0.4064\n",
      "Epoch 55/200\n",
      " - 5s - loss: 0.4079\n",
      "Epoch 56/200\n",
      " - 6s - loss: 0.4036\n",
      "Epoch 57/200\n",
      " - 6s - loss: 0.4027\n",
      "Epoch 58/200\n",
      " - 6s - loss: 0.4085\n",
      "Epoch 59/200\n",
      " - 6s - loss: 0.4023\n",
      "Epoch 60/200\n",
      " - 6s - loss: 0.4305\n",
      "Epoch 61/200\n",
      " - 6s - loss: 0.4291\n",
      "Epoch 62/200\n",
      " - 7s - loss: 0.4160\n",
      "Epoch 63/200\n",
      " - 7s - loss: 0.4028\n",
      "Epoch 64/200\n",
      " - 5s - loss: 0.4037\n",
      "Epoch 65/200\n",
      " - 5s - loss: 0.3972\n",
      "Epoch 66/200\n",
      " - 5s - loss: 0.4179\n",
      "Epoch 67/200\n",
      " - 5s - loss: 0.4195\n",
      "Epoch 68/200\n",
      " - 5s - loss: 0.4036\n",
      "Epoch 69/200\n",
      " - 5s - loss: 0.4030\n",
      "Epoch 70/200\n",
      " - 5s - loss: 0.4033\n",
      "Epoch 71/200\n",
      " - 5s - loss: 0.4021\n",
      "Epoch 72/200\n",
      " - 5s - loss: 0.4177\n",
      "Epoch 73/200\n",
      " - 5s - loss: 0.4171\n",
      "Epoch 74/200\n",
      " - 5s - loss: 0.4098\n",
      "Epoch 75/200\n",
      " - 5s - loss: 0.4021\n",
      "Epoch 76/200\n",
      " - 5s - loss: 0.3944\n",
      "Epoch 77/200\n",
      " - 5s - loss: 0.3983\n",
      "Epoch 78/200\n",
      " - 5s - loss: 0.4079\n",
      "Epoch 79/200\n",
      " - 5s - loss: 0.4023\n",
      "Epoch 80/200\n",
      " - 5s - loss: 0.3978\n",
      "Epoch 81/200\n",
      " - 5s - loss: 0.3973\n",
      "Epoch 82/200\n",
      " - 5s - loss: 0.3915\n",
      "Epoch 83/200\n",
      " - 5s - loss: 0.4035\n",
      "Epoch 84/200\n",
      " - 5s - loss: 0.4069\n",
      "Epoch 85/200\n",
      " - 5s - loss: 0.4039\n",
      "Epoch 86/200\n",
      " - 5s - loss: 0.4114\n",
      "Epoch 87/200\n",
      " - 5s - loss: 0.3922\n",
      "Epoch 88/200\n",
      " - 6s - loss: 0.4037\n",
      "Epoch 89/200\n",
      " - 5s - loss: 0.4027\n",
      "Epoch 90/200\n",
      " - 5s - loss: 0.3896\n",
      "Epoch 91/200\n",
      " - 5s - loss: 0.3935\n",
      "Epoch 92/200\n",
      " - 5s - loss: 0.4022\n",
      "Epoch 93/200\n",
      " - 5s - loss: 0.3921\n",
      "Epoch 94/200\n",
      " - 5s - loss: 0.4013\n",
      "Epoch 95/200\n",
      " - 6s - loss: 0.4075\n",
      "Epoch 96/200\n",
      " - 6s - loss: 0.4051\n",
      "Epoch 97/200\n",
      " - 7s - loss: 0.3940\n",
      "Epoch 98/200\n",
      " - 7s - loss: 0.3858\n",
      "Epoch 99/200\n",
      " - 6s - loss: 0.3900\n",
      "Epoch 100/200\n",
      " - 6s - loss: 0.3915\n",
      "Epoch 101/200\n",
      " - 6s - loss: 0.3969\n",
      "Epoch 102/200\n",
      " - 6s - loss: 0.3957\n",
      "Epoch 103/200\n",
      " - 6s - loss: 0.4009\n",
      "Epoch 104/200\n",
      " - 6s - loss: 0.3886\n",
      "Epoch 105/200\n",
      " - 5s - loss: 0.4164\n",
      "Epoch 106/200\n",
      " - 6s - loss: 0.3852\n",
      "Epoch 107/200\n",
      " - 5s - loss: 0.3999\n",
      "Epoch 108/200\n",
      " - 5s - loss: 0.3910\n",
      "Epoch 109/200\n",
      " - 5s - loss: 0.3862\n",
      "Epoch 110/200\n",
      " - 6s - loss: 0.3853\n",
      "Epoch 111/200\n",
      " - 6s - loss: 0.3893\n",
      "Epoch 112/200\n",
      " - 5s - loss: 0.3934\n",
      "Epoch 113/200\n",
      " - 5s - loss: 0.4070\n",
      "Epoch 114/200\n",
      " - 6s - loss: 0.3945\n",
      "Epoch 115/200\n",
      " - 6s - loss: 0.3982\n",
      "Epoch 116/200\n",
      " - 5s - loss: 0.3953\n",
      "Epoch 117/200\n",
      " - 5s - loss: 0.3858\n",
      "Epoch 118/200\n",
      " - 5s - loss: 0.3882\n",
      "Epoch 119/200\n",
      " - 5s - loss: 0.3905\n",
      "Epoch 120/200\n",
      " - 5s - loss: 0.4025\n",
      "Epoch 121/200\n",
      " - 5s - loss: 0.3922\n",
      "Epoch 122/200\n",
      " - 5s - loss: 0.3929\n",
      "Epoch 123/200\n",
      " - 5s - loss: 0.3916\n",
      "Epoch 124/200\n",
      " - 5s - loss: 0.3867\n",
      "Epoch 125/200\n",
      " - 5s - loss: 0.3869\n",
      "Epoch 126/200\n",
      " - 5s - loss: 0.3875\n",
      "Epoch 127/200\n",
      " - 5s - loss: 0.4062\n",
      "Epoch 128/200\n",
      " - 5s - loss: 0.3972\n",
      "Epoch 129/200\n",
      " - 5s - loss: 0.3902\n",
      "Epoch 130/200\n",
      " - 5s - loss: 0.3982\n",
      "Epoch 131/200\n",
      " - 5s - loss: 0.3896\n",
      "Epoch 132/200\n",
      " - 5s - loss: 0.3910\n",
      "Epoch 133/200\n",
      " - 5s - loss: 0.3974\n",
      "Epoch 134/200\n",
      " - 5s - loss: 0.3898\n",
      "Epoch 135/200\n",
      " - 5s - loss: 0.3955\n",
      "Epoch 136/200\n",
      " - 5s - loss: 0.4068\n",
      "Epoch 137/200\n",
      " - 5s - loss: 0.3860\n",
      "Epoch 138/200\n",
      " - 5s - loss: 0.3902\n",
      "Epoch 139/200\n",
      " - 5s - loss: 0.3930\n",
      "Epoch 140/200\n",
      " - 5s - loss: 0.3879\n",
      "Epoch 141/200\n",
      " - 5s - loss: 0.3911\n",
      "Epoch 142/200\n",
      " - 5s - loss: 0.3811\n",
      "Epoch 143/200\n",
      " - 6s - loss: 0.3919\n",
      "Epoch 144/200\n",
      " - 6s - loss: 0.3896\n",
      "Epoch 145/200\n",
      " - 6s - loss: 0.3986\n",
      "Epoch 146/200\n",
      " - 5s - loss: 0.3806\n",
      "Epoch 147/200\n",
      " - 6s - loss: 0.3853\n",
      "Epoch 148/200\n",
      " - 5s - loss: 0.4052\n",
      "Epoch 149/200\n",
      " - 6s - loss: 0.3973\n",
      "Epoch 150/200\n",
      " - 6s - loss: 0.3977\n",
      "Epoch 151/200\n",
      " - 5s - loss: 0.3921\n",
      "Epoch 152/200\n",
      " - 5s - loss: 0.3861\n",
      "Epoch 153/200\n",
      " - 6s - loss: 0.3957\n",
      "Epoch 154/200\n",
      " - 5s - loss: 0.3788\n",
      "Epoch 155/200\n",
      " - 6s - loss: 0.3749\n",
      "Epoch 156/200\n",
      " - 5s - loss: 0.3903\n",
      "Epoch 157/200\n",
      " - 6s - loss: 0.3855\n",
      "Epoch 158/200\n",
      " - 5s - loss: 0.3814\n",
      "Epoch 159/200\n",
      " - 6s - loss: 0.3775\n",
      "Epoch 160/200\n",
      " - 5s - loss: 0.3856\n",
      "Epoch 161/200\n",
      " - 5s - loss: 0.3763\n",
      "Epoch 162/200\n",
      " - 6s - loss: 0.3937\n",
      "Epoch 163/200\n",
      " - 5s - loss: 0.3828\n",
      "Epoch 164/200\n",
      " - 6s - loss: 0.3754\n",
      "Epoch 165/200\n",
      " - 5s - loss: 0.3894\n",
      "Epoch 166/200\n",
      " - 5s - loss: 0.3822\n",
      "Epoch 167/200\n",
      " - 5s - loss: 0.3836\n",
      "Epoch 168/200\n",
      " - 5s - loss: 0.3882\n",
      "Epoch 169/200\n",
      " - 5s - loss: 0.3853\n",
      "Epoch 170/200\n",
      " - 5s - loss: 0.3836\n",
      "Epoch 171/200\n",
      " - 6s - loss: 0.3767\n",
      "Epoch 172/200\n",
      " - 6s - loss: 0.3785\n",
      "Epoch 173/200\n",
      " - 5s - loss: 0.3878\n",
      "Epoch 174/200\n",
      " - 5s - loss: 0.3744\n",
      "Epoch 175/200\n",
      " - 5s - loss: 0.3776\n",
      "Epoch 176/200\n",
      " - 5s - loss: 0.3751\n",
      "Epoch 177/200\n",
      " - 5s - loss: 0.3921\n",
      "Epoch 178/200\n",
      " - 5s - loss: 0.3746\n",
      "Epoch 179/200\n",
      " - 5s - loss: 0.3764\n",
      "Epoch 180/200\n",
      " - 5s - loss: 0.3797\n",
      "Epoch 181/200\n",
      " - 5s - loss: 0.3786\n",
      "Epoch 182/200\n",
      " - 5s - loss: 0.3778\n",
      "Epoch 183/200\n",
      " - 5s - loss: 0.3704\n",
      "Epoch 184/200\n",
      " - 5s - loss: 0.3775\n",
      "Epoch 185/200\n",
      " - 5s - loss: 0.3872\n",
      "Epoch 186/200\n",
      " - 5s - loss: 0.3811\n",
      "Epoch 187/200\n",
      " - 5s - loss: 0.3911\n",
      "Epoch 188/200\n",
      " - 5s - loss: 0.3839\n",
      "Epoch 189/200\n",
      " - 5s - loss: 0.3842\n",
      "Epoch 190/200\n",
      " - 5s - loss: 0.3880\n",
      "Epoch 191/200\n",
      " - 5s - loss: 0.3855\n",
      "Epoch 192/200\n",
      " - 5s - loss: 0.3690\n",
      "Epoch 193/200\n",
      " - 5s - loss: 0.3788\n",
      "Epoch 194/200\n",
      " - 5s - loss: 0.3837\n",
      "Epoch 195/200\n",
      " - 5s - loss: 0.3661\n",
      "Epoch 196/200\n",
      " - 5s - loss: 0.3719\n",
      "Epoch 197/200\n",
      " - 5s - loss: 0.3765\n",
      "Epoch 198/200\n",
      " - 5s - loss: 0.3746\n",
      "Epoch 199/200\n",
      " - 5s - loss: 0.3678\n",
      "Epoch 200/200\n",
      " - 5s - loss: 0.3933\n"
     ]
    }
   ],
   "source": [
    "model_lstm_1 = Sequential()\n",
    "model_lstm_1.add(LSTM(10, input_shape=(1, train_dataset_shifted.shape[1])))\n",
    "model_lstm_1.add(Dense(19))\n",
    "model_lstm_1.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# history = model_lstm_1.fit(train_dataset, train_dataset_shifted_1, verbose=2, shuffle=False, epochs=model_epoches, validation_data=(test_dataset_shaped ,test_dataset_shifted_1), batch_size= 200)\n",
    "history = model_lstm_1.fit(train_dataset, train_dataset_shifted_1, verbose=2, shuffle=False, epochs=model_epoches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set 2\n",
    "- system.cpu.total.pct'\n",
    "- system.cpu.user.pct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu.total.pct</th>\n",
       "      <th>system.cpu.user.pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.279101</td>\n",
       "      <td>-0.217114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.246603</td>\n",
       "      <td>-0.235164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.067553</td>\n",
       "      <td>-0.196552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.198013</td>\n",
       "      <td>-0.174264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.212231</td>\n",
       "      <td>-0.215230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   system.cpu.total.pct  system.cpu.user.pct\n",
       "0             -0.279101            -0.217114\n",
       "1             -0.246603            -0.235164\n",
       "2             -0.067553            -0.196552\n",
       "3             -0.198013            -0.174264\n",
       "4             -0.212231            -0.215230"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_shifted_2 = train_dataset_shifted[[\n",
    "    'system.cpu.total.pct',\n",
    "    'system.cpu.user.pct']]\n",
    "\n",
    "train_dataset_shifted_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 8s - loss: 1774.6043\n",
      "Epoch 2/200\n",
      " - 5s - loss: 999.3749\n",
      "Epoch 3/200\n",
      " - 5s - loss: 155.4733\n",
      "Epoch 4/200\n",
      " - 5s - loss: 58.3108\n",
      "Epoch 5/200\n",
      " - 5s - loss: 107.1113\n",
      "Epoch 6/200\n",
      " - 5s - loss: 1.9421\n",
      "Epoch 7/200\n",
      " - 5s - loss: 13.7248\n",
      "Epoch 8/200\n",
      " - 5s - loss: 58.8871\n",
      "Epoch 9/200\n",
      " - 5s - loss: 6.3000\n",
      "Epoch 10/200\n",
      " - 5s - loss: 0.8512\n",
      "Epoch 11/200\n",
      " - 5s - loss: 0.7724\n",
      "Epoch 12/200\n",
      " - 5s - loss: 0.5874\n",
      "Epoch 13/200\n",
      " - 5s - loss: 0.3688\n",
      "Epoch 14/200\n",
      " - 5s - loss: 0.2463\n",
      "Epoch 15/200\n",
      " - 5s - loss: 0.3263\n",
      "Epoch 16/200\n",
      " - 5s - loss: 0.2472\n",
      "Epoch 17/200\n",
      " - 5s - loss: 0.2206\n",
      "Epoch 18/200\n",
      " - 5s - loss: 0.2256\n",
      "Epoch 19/200\n",
      " - 5s - loss: 0.2027\n",
      "Epoch 20/200\n",
      " - 5s - loss: 0.1792\n",
      "Epoch 21/200\n",
      " - 5s - loss: 0.1819\n",
      "Epoch 22/200\n",
      " - 5s - loss: 0.1359\n",
      "Epoch 23/200\n",
      " - 5s - loss: 0.1423\n",
      "Epoch 24/200\n",
      " - 5s - loss: 0.1510\n",
      "Epoch 25/200\n",
      " - 5s - loss: 0.1122\n",
      "Epoch 26/200\n",
      " - 5s - loss: 0.1134\n",
      "Epoch 27/200\n",
      " - 5s - loss: 0.0990\n",
      "Epoch 28/200\n",
      " - 5s - loss: 0.1003\n",
      "Epoch 29/200\n",
      " - 5s - loss: 0.0928\n",
      "Epoch 30/200\n",
      " - 5s - loss: 0.0907\n",
      "Epoch 31/200\n",
      " - 5s - loss: 0.0902\n",
      "Epoch 32/200\n",
      " - 5s - loss: 0.0870\n",
      "Epoch 33/200\n",
      " - 5s - loss: 0.0820\n",
      "Epoch 34/200\n",
      " - 5s - loss: 0.0785\n",
      "Epoch 35/200\n",
      " - 5s - loss: 0.0765\n",
      "Epoch 36/200\n",
      " - 5s - loss: 0.0810\n",
      "Epoch 37/200\n",
      " - 5s - loss: 0.0712\n",
      "Epoch 38/200\n",
      " - 5s - loss: 0.0804\n",
      "Epoch 39/200\n",
      " - 5s - loss: 0.0705\n",
      "Epoch 40/200\n",
      " - 5s - loss: 0.0736\n",
      "Epoch 41/200\n",
      " - 5s - loss: 0.1850\n",
      "Epoch 42/200\n",
      " - 5s - loss: 0.0684\n",
      "Epoch 43/200\n",
      " - 5s - loss: 0.0680\n",
      "Epoch 44/200\n",
      " - 5s - loss: 0.0620\n",
      "Epoch 45/200\n",
      " - 5s - loss: 0.0606\n",
      "Epoch 46/200\n",
      " - 5s - loss: 0.0766\n",
      "Epoch 47/200\n",
      " - 5s - loss: 0.0595\n",
      "Epoch 48/200\n",
      " - 5s - loss: 0.0589\n",
      "Epoch 49/200\n",
      " - 5s - loss: 0.0573\n",
      "Epoch 50/200\n",
      " - 5s - loss: 0.0548\n",
      "Epoch 51/200\n",
      " - 5s - loss: 0.0613\n",
      "Epoch 52/200\n",
      " - 5s - loss: 0.0641\n",
      "Epoch 53/200\n",
      " - 5s - loss: 0.0591\n",
      "Epoch 54/200\n",
      " - 5s - loss: 0.0571\n",
      "Epoch 55/200\n",
      " - 5s - loss: 0.0571\n",
      "Epoch 56/200\n",
      " - 5s - loss: 0.0563\n",
      "Epoch 57/200\n",
      " - 5s - loss: 0.0563\n",
      "Epoch 58/200\n",
      " - 5s - loss: 0.0597\n",
      "Epoch 59/200\n",
      " - 5s - loss: 0.0529\n",
      "Epoch 60/200\n",
      " - 5s - loss: 0.7018\n",
      "Epoch 61/200\n",
      " - 5s - loss: 0.0517\n",
      "Epoch 62/200\n",
      " - 5s - loss: 0.0554\n",
      "Epoch 63/200\n",
      " - 5s - loss: 0.0522\n",
      "Epoch 64/200\n",
      " - 5s - loss: 0.0583\n",
      "Epoch 65/200\n",
      " - 5s - loss: 0.0477\n",
      "Epoch 66/200\n",
      " - 5s - loss: 0.0510\n",
      "Epoch 67/200\n",
      " - 5s - loss: 0.0474\n",
      "Epoch 68/200\n",
      " - 5s - loss: 0.0636\n",
      "Epoch 69/200\n",
      " - 5s - loss: 0.0489\n",
      "Epoch 70/200\n",
      " - 5s - loss: 0.0528\n",
      "Epoch 71/200\n",
      " - 5s - loss: 0.0548\n",
      "Epoch 72/200\n",
      " - 5s - loss: 0.0523\n",
      "Epoch 73/200\n",
      " - 5s - loss: 0.0489\n",
      "Epoch 74/200\n",
      " - 5s - loss: 0.0471\n",
      "Epoch 75/200\n",
      " - 5s - loss: 0.0487\n",
      "Epoch 76/200\n",
      " - 5s - loss: 0.0693\n",
      "Epoch 77/200\n",
      " - 5s - loss: 0.0573\n",
      "Epoch 78/200\n",
      " - 5s - loss: 1.0893\n",
      "Epoch 79/200\n",
      " - 5s - loss: 1.8518\n",
      "Epoch 80/200\n",
      " - 5s - loss: 0.0375\n",
      "Epoch 81/200\n",
      " - 5s - loss: 0.0385\n",
      "Epoch 82/200\n",
      " - 5s - loss: 0.0782\n",
      "Epoch 83/200\n",
      " - 5s - loss: 0.0418\n",
      "Epoch 84/200\n",
      " - 5s - loss: 0.0366\n",
      "Epoch 85/200\n",
      " - 5s - loss: 0.0400\n",
      "Epoch 86/200\n",
      " - 5s - loss: 0.0432\n",
      "Epoch 87/200\n",
      " - 5s - loss: 0.0442\n",
      "Epoch 88/200\n",
      " - 5s - loss: 0.0436\n",
      "Epoch 89/200\n",
      " - 5s - loss: 0.0488\n",
      "Epoch 90/200\n",
      " - 5s - loss: 0.1332\n",
      "Epoch 91/200\n",
      " - 5s - loss: 0.0448\n",
      "Epoch 92/200\n",
      " - 5s - loss: 0.0449\n",
      "Epoch 93/200\n",
      " - 5s - loss: 0.0783\n",
      "Epoch 94/200\n",
      " - 5s - loss: 0.0437\n",
      "Epoch 95/200\n",
      " - 5s - loss: 0.0426\n",
      "Epoch 96/200\n",
      " - 5s - loss: 0.0455\n",
      "Epoch 97/200\n",
      " - 5s - loss: 0.0562\n",
      "Epoch 98/200\n",
      " - 5s - loss: 0.0444\n",
      "Epoch 99/200\n",
      " - 5s - loss: 0.0433\n",
      "Epoch 100/200\n",
      " - 6s - loss: 0.0441\n",
      "Epoch 101/200\n",
      " - 5s - loss: 0.0508\n",
      "Epoch 102/200\n",
      " - 5s - loss: 0.0664\n",
      "Epoch 103/200\n",
      " - 5s - loss: 0.0422\n",
      "Epoch 104/200\n",
      " - 5s - loss: 0.0512\n",
      "Epoch 105/200\n",
      " - 5s - loss: 0.0462\n",
      "Epoch 106/200\n",
      " - 5s - loss: 0.0433\n",
      "Epoch 107/200\n",
      " - 5s - loss: 0.0456\n",
      "Epoch 108/200\n",
      " - 5s - loss: 0.0447\n",
      "Epoch 109/200\n",
      " - 5s - loss: 0.0564\n",
      "Epoch 110/200\n",
      " - 5s - loss: 0.0440\n",
      "Epoch 111/200\n",
      " - 5s - loss: 0.0443\n",
      "Epoch 112/200\n",
      " - 5s - loss: 0.0442\n",
      "Epoch 113/200\n",
      " - 5s - loss: 0.0450\n",
      "Epoch 114/200\n",
      " - 5s - loss: 0.6804\n",
      "Epoch 115/200\n",
      " - 5s - loss: 0.0431\n",
      "Epoch 116/200\n",
      " - 5s - loss: 0.0337\n",
      "Epoch 117/200\n",
      " - 5s - loss: 0.0968\n",
      "Epoch 118/200\n",
      " - 5s - loss: 0.0404\n",
      "Epoch 119/200\n",
      " - 5s - loss: 0.0391\n",
      "Epoch 120/200\n",
      " - 5s - loss: 0.0386\n",
      "Epoch 121/200\n",
      " - 5s - loss: 0.0403\n",
      "Epoch 122/200\n",
      " - 5s - loss: 0.0440\n",
      "Epoch 123/200\n",
      " - 5s - loss: 0.0445\n",
      "Epoch 124/200\n",
      " - 5s - loss: 0.0487\n",
      "Epoch 125/200\n",
      " - 5s - loss: 0.0414\n",
      "Epoch 126/200\n",
      " - 5s - loss: 0.0439\n",
      "Epoch 127/200\n",
      " - 5s - loss: 0.0415\n",
      "Epoch 128/200\n",
      " - 6s - loss: 0.0428\n",
      "Epoch 129/200\n",
      " - 5s - loss: 0.0406\n",
      "Epoch 130/200\n",
      " - 5s - loss: 0.0412\n",
      "Epoch 131/200\n",
      " - 5s - loss: 0.0757\n",
      "Epoch 132/200\n",
      " - 5s - loss: 0.0748\n",
      "Epoch 133/200\n",
      " - 5s - loss: 0.0330\n",
      "Epoch 134/200\n",
      " - 5s - loss: 0.0461\n",
      "Epoch 135/200\n",
      " - 5s - loss: 0.0382\n",
      "Epoch 136/200\n",
      " - 5s - loss: 0.0407\n",
      "Epoch 137/200\n",
      " - 5s - loss: 0.0438\n",
      "Epoch 138/200\n",
      " - 5s - loss: 0.0381\n",
      "Epoch 139/200\n",
      " - 5s - loss: 0.0411\n",
      "Epoch 140/200\n",
      " - 5s - loss: 0.0741\n",
      "Epoch 141/200\n",
      " - 5s - loss: 0.0421\n",
      "Epoch 142/200\n",
      " - 5s - loss: 0.0378\n",
      "Epoch 143/200\n",
      " - 5s - loss: 0.0376\n",
      "Epoch 144/200\n",
      " - 5s - loss: 0.0391\n",
      "Epoch 145/200\n",
      " - 5s - loss: 0.0398\n",
      "Epoch 146/200\n",
      " - 5s - loss: 0.0486\n",
      "Epoch 147/200\n",
      " - 5s - loss: 0.0420\n",
      "Epoch 148/200\n",
      " - 5s - loss: 0.1066\n",
      "Epoch 149/200\n",
      " - 5s - loss: 0.0288\n",
      "Epoch 150/200\n",
      " - 5s - loss: 0.0356\n",
      "Epoch 151/200\n",
      " - 5s - loss: 0.0520\n",
      "Epoch 152/200\n",
      " - 5s - loss: 0.0401\n",
      "Epoch 153/200\n",
      " - 5s - loss: 0.0362\n",
      "Epoch 154/200\n",
      " - 5s - loss: 0.0378\n",
      "Epoch 155/200\n",
      " - 5s - loss: 0.0408\n",
      "Epoch 156/200\n",
      " - 5s - loss: 0.0388\n",
      "Epoch 157/200\n",
      " - 6s - loss: 0.0398\n",
      "Epoch 158/200\n",
      " - 5s - loss: 0.0413\n",
      "Epoch 159/200\n",
      " - 5s - loss: 0.0389\n",
      "Epoch 160/200\n",
      " - 5s - loss: 0.0380\n",
      "Epoch 161/200\n",
      " - 5s - loss: 0.0445\n",
      "Epoch 162/200\n",
      " - 5s - loss: 0.0414\n",
      "Epoch 163/200\n",
      " - 5s - loss: 0.0390\n",
      "Epoch 164/200\n",
      " - 5s - loss: 0.0384\n",
      "Epoch 165/200\n",
      " - 5s - loss: 25.8307\n",
      "Epoch 166/200\n",
      " - 5s - loss: 0.0481\n",
      "Epoch 167/200\n",
      " - 5s - loss: 0.0394\n",
      "Epoch 168/200\n",
      " - 5s - loss: 0.0348\n",
      "Epoch 169/200\n",
      " - 5s - loss: 0.0335\n",
      "Epoch 170/200\n",
      " - 5s - loss: 0.0350\n",
      "Epoch 171/200\n",
      " - 5s - loss: 0.0404\n",
      "Epoch 172/200\n",
      " - 5s - loss: 0.0409\n",
      "Epoch 173/200\n",
      " - 5s - loss: 0.0348\n",
      "Epoch 174/200\n",
      " - 5s - loss: 0.0365\n",
      "Epoch 175/200\n",
      " - 5s - loss: 0.0385\n",
      "Epoch 176/200\n",
      " - 5s - loss: 0.0352\n",
      "Epoch 177/200\n",
      " - 5s - loss: 0.0400\n",
      "Epoch 178/200\n",
      " - 6s - loss: 0.0341\n",
      "Epoch 179/200\n",
      " - 5s - loss: 0.0384\n",
      "Epoch 180/200\n",
      " - 5s - loss: 0.0408\n",
      "Epoch 181/200\n",
      " - 5s - loss: 0.0461\n",
      "Epoch 182/200\n",
      " - 5s - loss: 0.0361\n",
      "Epoch 183/200\n",
      " - 5s - loss: 0.0384\n",
      "Epoch 184/200\n",
      " - 5s - loss: 0.0390\n",
      "Epoch 185/200\n",
      " - 5s - loss: 0.0666\n",
      "Epoch 186/200\n",
      " - 5s - loss: 0.0357\n",
      "Epoch 187/200\n",
      " - 5s - loss: 0.0294\n",
      "Epoch 188/200\n",
      " - 5s - loss: 0.0354\n",
      "Epoch 189/200\n",
      " - 5s - loss: 0.0412\n",
      "Epoch 190/200\n",
      " - 5s - loss: 0.0385\n",
      "Epoch 191/200\n",
      " - 5s - loss: 0.0359\n",
      "Epoch 192/200\n",
      " - 5s - loss: 0.0372\n",
      "Epoch 193/200\n",
      " - 5s - loss: 0.0375\n",
      "Epoch 194/200\n",
      " - 5s - loss: 0.0399\n",
      "Epoch 195/200\n",
      " - 5s - loss: 0.0385\n",
      "Epoch 196/200\n",
      " - 5s - loss: 0.0351\n",
      "Epoch 197/200\n",
      " - 5s - loss: 0.0368\n",
      "Epoch 198/200\n",
      " - 5s - loss: 0.0380\n",
      "Epoch 199/200\n",
      " - 5s - loss: 0.0357\n",
      "Epoch 200/200\n",
      " - 5s - loss: 0.0360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8c08b4b00>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm_2 = Sequential()\n",
    "model_lstm_2.add(LSTM(10, input_shape=(1, train_dataset_shifted.shape[1]), activation='softplus', recurrent_activation='linear'))\n",
    "model_lstm_2.add(Dense(2))\n",
    "model_lstm_2.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model_lstm_2.fit(train_dataset, train_dataset_shifted_2, verbose=2, shuffle=False, epochs=model_epoches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set 3\n",
    "- jolokia.metrics.memory.heap_memory_usage.committed'\n",
    "- jolokia.metrics.memory.heap_memory_usage.max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jolokia.metrics.memory.heap_memory_usage.committed</th>\n",
       "      <th>jolokia.metrics.memory.heap_memory_usage.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.808558</td>\n",
       "      <td>0.808558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.206531</td>\n",
       "      <td>0.206531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.206531</td>\n",
       "      <td>0.206531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.206531</td>\n",
       "      <td>0.206531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.206531</td>\n",
       "      <td>0.206531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   jolokia.metrics.memory.heap_memory_usage.committed  \\\n",
       "0                                           0.808558    \n",
       "1                                           0.206531    \n",
       "2                                           0.206531    \n",
       "3                                           0.206531    \n",
       "4                                           0.206531    \n",
       "\n",
       "   jolokia.metrics.memory.heap_memory_usage.max  \n",
       "0                                      0.808558  \n",
       "1                                      0.206531  \n",
       "2                                      0.206531  \n",
       "3                                      0.206531  \n",
       "4                                      0.206531  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_shifted_3 = train_dataset_shifted[[\n",
    "    'jolokia.metrics.memory.heap_memory_usage.committed',\n",
    "    'jolokia.metrics.memory.heap_memory_usage.max']]\n",
    "\n",
    "train_dataset_shifted_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 8s - loss: 197.5604\n",
      "Epoch 2/200\n",
      " - 5s - loss: 12.7361\n",
      "Epoch 3/200\n",
      " - 5s - loss: 3.7213\n",
      "Epoch 4/200\n",
      " - 5s - loss: 2.2442\n",
      "Epoch 5/200\n",
      " - 5s - loss: 154.7669\n",
      "Epoch 6/200\n",
      " - 5s - loss: 1.0877\n",
      "Epoch 7/200\n",
      " - 5s - loss: 0.8650\n",
      "Epoch 8/200\n",
      " - 5s - loss: 0.8230\n",
      "Epoch 9/200\n",
      " - 5s - loss: 0.7936\n",
      "Epoch 10/200\n",
      " - 5s - loss: 0.8041\n",
      "Epoch 11/200\n",
      " - 5s - loss: 0.8241\n",
      "Epoch 12/200\n",
      " - 5s - loss: 0.8028\n",
      "Epoch 13/200\n",
      " - 5s - loss: 0.7833\n",
      "Epoch 14/200\n",
      " - 5s - loss: 0.7643\n",
      "Epoch 15/200\n",
      " - 5s - loss: 0.8505\n",
      "Epoch 16/200\n",
      " - 5s - loss: 0.7915\n",
      "Epoch 17/200\n",
      " - 5s - loss: 0.7045\n",
      "Epoch 18/200\n",
      " - 5s - loss: 0.7092\n",
      "Epoch 19/200\n",
      " - 5s - loss: 0.7196\n",
      "Epoch 20/200\n",
      " - 5s - loss: 0.7039\n",
      "Epoch 21/200\n",
      " - 5s - loss: 0.6966\n",
      "Epoch 22/200\n",
      " - 5s - loss: 1.9564\n",
      "Epoch 23/200\n",
      " - 5s - loss: 0.6911\n",
      "Epoch 24/200\n",
      " - 5s - loss: 0.6945\n",
      "Epoch 25/200\n",
      " - 5s - loss: 0.6818\n",
      "Epoch 26/200\n",
      " - 5s - loss: 0.6894\n",
      "Epoch 27/200\n",
      " - 5s - loss: 0.6854\n",
      "Epoch 28/200\n",
      " - 5s - loss: 0.6891\n",
      "Epoch 29/200\n",
      " - 5s - loss: 0.6737\n",
      "Epoch 30/200\n",
      " - 5s - loss: 0.9168\n",
      "Epoch 31/200\n",
      " - 5s - loss: 0.6743\n",
      "Epoch 32/200\n",
      " - 5s - loss: 0.6682\n",
      "Epoch 33/200\n",
      " - 5s - loss: 0.6753\n",
      "Epoch 34/200\n",
      " - 5s - loss: 0.6651\n",
      "Epoch 35/200\n",
      " - 5s - loss: 0.6816\n",
      "Epoch 36/200\n",
      " - 5s - loss: 0.6666\n",
      "Epoch 37/200\n",
      " - 5s - loss: 0.6555\n",
      "Epoch 38/200\n",
      " - 5s - loss: 0.6696\n",
      "Epoch 39/200\n",
      " - 5s - loss: 0.6912\n",
      "Epoch 40/200\n",
      " - 5s - loss: 0.6653\n",
      "Epoch 41/200\n",
      " - 5s - loss: 0.6680\n",
      "Epoch 42/200\n",
      " - 5s - loss: 0.6594\n",
      "Epoch 43/200\n",
      " - 5s - loss: 0.6862\n",
      "Epoch 44/200\n",
      " - 5s - loss: 0.6521\n",
      "Epoch 45/200\n",
      " - 5s - loss: 0.6532\n",
      "Epoch 46/200\n",
      " - 5s - loss: 0.6532\n",
      "Epoch 47/200\n",
      " - 5s - loss: 0.6516\n",
      "Epoch 48/200\n",
      " - 5s - loss: 0.6493\n",
      "Epoch 49/200\n",
      " - 5s - loss: 0.6515\n",
      "Epoch 50/200\n",
      " - 5s - loss: 0.6550\n",
      "Epoch 51/200\n",
      " - 5s - loss: 0.6475\n",
      "Epoch 52/200\n",
      " - 5s - loss: 0.6569\n",
      "Epoch 53/200\n",
      " - 5s - loss: 0.6499\n",
      "Epoch 54/200\n",
      " - 5s - loss: 0.6506\n",
      "Epoch 55/200\n",
      " - 5s - loss: 0.6470\n",
      "Epoch 56/200\n",
      " - 5s - loss: 0.6501\n",
      "Epoch 57/200\n",
      " - 5s - loss: 0.6417\n",
      "Epoch 58/200\n",
      " - 5s - loss: 0.6492\n",
      "Epoch 59/200\n",
      " - 5s - loss: 0.6401\n",
      "Epoch 60/200\n",
      " - 5s - loss: 0.6386\n",
      "Epoch 61/200\n",
      " - 5s - loss: 0.6501\n",
      "Epoch 62/200\n",
      " - 5s - loss: 0.6340\n",
      "Epoch 63/200\n",
      " - 5s - loss: 0.6357\n",
      "Epoch 64/200\n",
      " - 5s - loss: 0.6350\n",
      "Epoch 65/200\n",
      " - 5s - loss: 0.6323\n",
      "Epoch 66/200\n",
      " - 5s - loss: 0.6384\n",
      "Epoch 67/200\n",
      " - 5s - loss: 0.6336\n",
      "Epoch 68/200\n",
      " - 5s - loss: 0.6275\n",
      "Epoch 69/200\n",
      " - 5s - loss: 0.6410\n",
      "Epoch 70/200\n",
      " - 5s - loss: 0.6207\n",
      "Epoch 71/200\n",
      " - 5s - loss: 0.6227\n",
      "Epoch 72/200\n",
      " - 5s - loss: 0.6259\n",
      "Epoch 73/200\n",
      " - 5s - loss: 0.6234\n",
      "Epoch 74/200\n",
      " - 5s - loss: 0.8781\n",
      "Epoch 75/200\n",
      " - 5s - loss: 0.6246\n",
      "Epoch 76/200\n",
      " - 5s - loss: 0.6181\n",
      "Epoch 77/200\n",
      " - 5s - loss: 0.6203\n",
      "Epoch 78/200\n",
      " - 5s - loss: 0.6166\n",
      "Epoch 79/200\n",
      " - 5s - loss: 0.6670\n",
      "Epoch 80/200\n",
      " - 5s - loss: 0.6162\n",
      "Epoch 81/200\n",
      " - 5s - loss: 0.6079\n",
      "Epoch 82/200\n",
      " - 5s - loss: 0.6181\n",
      "Epoch 83/200\n",
      " - 5s - loss: 0.6118\n",
      "Epoch 84/200\n",
      " - 5s - loss: 0.6137\n",
      "Epoch 85/200\n",
      " - 5s - loss: 0.6203\n",
      "Epoch 86/200\n",
      " - 5s - loss: 0.6121\n",
      "Epoch 87/200\n",
      " - 5s - loss: 0.6155\n",
      "Epoch 88/200\n",
      " - 5s - loss: 0.6074\n",
      "Epoch 89/200\n",
      " - 5s - loss: 0.6010\n",
      "Epoch 90/200\n",
      " - 5s - loss: 0.6757\n",
      "Epoch 91/200\n",
      " - 5s - loss: 0.6045\n",
      "Epoch 92/200\n",
      " - 5s - loss: 0.6038\n",
      "Epoch 93/200\n",
      " - 5s - loss: 0.6162\n",
      "Epoch 94/200\n",
      " - 5s - loss: 0.6055\n",
      "Epoch 95/200\n",
      " - 5s - loss: 0.6078\n",
      "Epoch 96/200\n",
      " - 5s - loss: 0.6027\n",
      "Epoch 97/200\n",
      " - 5s - loss: 0.6012\n",
      "Epoch 98/200\n",
      " - 5s - loss: 0.5980\n",
      "Epoch 99/200\n",
      " - 6s - loss: 0.6056\n",
      "Epoch 100/200\n",
      " - 6s - loss: 0.6061\n",
      "Epoch 101/200\n",
      " - 5s - loss: 0.6028\n",
      "Epoch 102/200\n",
      " - 5s - loss: 0.6002\n",
      "Epoch 103/200\n",
      " - 5s - loss: 0.5988\n",
      "Epoch 104/200\n",
      " - 5s - loss: 0.6004\n",
      "Epoch 105/200\n",
      " - 5s - loss: 9.6104\n",
      "Epoch 106/200\n",
      " - 5s - loss: 0.7232\n",
      "Epoch 107/200\n",
      " - 5s - loss: 0.6003\n",
      "Epoch 108/200\n",
      " - 5s - loss: 0.5885\n",
      "Epoch 109/200\n",
      " - 5s - loss: 0.5951\n",
      "Epoch 110/200\n",
      " - 5s - loss: 0.5863\n",
      "Epoch 111/200\n",
      " - 5s - loss: 0.5875\n",
      "Epoch 112/200\n",
      " - 5s - loss: 0.5900\n",
      "Epoch 113/200\n",
      " - 5s - loss: 0.5915\n",
      "Epoch 114/200\n",
      " - 5s - loss: 0.5964\n",
      "Epoch 115/200\n",
      " - 5s - loss: 0.6095\n",
      "Epoch 116/200\n",
      " - 5s - loss: 0.6018\n",
      "Epoch 117/200\n",
      " - 5s - loss: 0.6027\n",
      "Epoch 118/200\n",
      " - 5s - loss: 0.5759\n",
      "Epoch 119/200\n",
      " - 5s - loss: 0.5968\n",
      "Epoch 120/200\n",
      " - 5s - loss: 0.5831\n",
      "Epoch 121/200\n",
      " - 5s - loss: 0.6124\n",
      "Epoch 122/200\n",
      " - 5s - loss: 0.6010\n",
      "Epoch 123/200\n",
      " - 5s - loss: 0.6014\n",
      "Epoch 124/200\n",
      " - 5s - loss: 0.5943\n",
      "Epoch 125/200\n",
      " - 5s - loss: 0.5842\n",
      "Epoch 126/200\n",
      " - 5s - loss: 1.5878\n",
      "Epoch 127/200\n",
      " - 5s - loss: 0.5953\n",
      "Epoch 128/200\n",
      " - 5s - loss: 0.5960\n",
      "Epoch 129/200\n",
      " - 5s - loss: 0.6383\n",
      "Epoch 130/200\n",
      " - 5s - loss: 0.5949\n",
      "Epoch 131/200\n",
      " - 5s - loss: 0.5983\n",
      "Epoch 132/200\n",
      " - 5s - loss: 0.5887\n",
      "Epoch 133/200\n",
      " - 5s - loss: 0.5938\n",
      "Epoch 134/200\n",
      " - 5s - loss: 0.5841\n",
      "Epoch 135/200\n",
      " - 5s - loss: 0.5977\n",
      "Epoch 136/200\n",
      " - 5s - loss: 0.5949\n",
      "Epoch 137/200\n",
      " - 5s - loss: 0.5884\n",
      "Epoch 138/200\n",
      " - 5s - loss: 0.5829\n",
      "Epoch 139/200\n",
      " - 5s - loss: 0.5923\n",
      "Epoch 140/200\n",
      " - 5s - loss: 0.5918\n",
      "Epoch 141/200\n",
      " - 5s - loss: 0.5977\n",
      "Epoch 142/200\n",
      " - 5s - loss: 0.6295\n",
      "Epoch 143/200\n",
      " - 5s - loss: 0.5987\n",
      "Epoch 144/200\n",
      " - 5s - loss: 0.5744\n",
      "Epoch 145/200\n",
      " - 5s - loss: 0.5885\n",
      "Epoch 146/200\n",
      " - 5s - loss: 0.5943\n",
      "Epoch 147/200\n",
      " - 5s - loss: 0.6008\n",
      "Epoch 148/200\n",
      " - 5s - loss: 0.5886\n",
      "Epoch 149/200\n",
      " - 5s - loss: 2.8450\n",
      "Epoch 150/200\n",
      " - 5s - loss: 0.7706\n",
      "Epoch 151/200\n",
      " - 5s - loss: 0.5852\n",
      "Epoch 152/200\n",
      " - 5s - loss: 0.5796\n",
      "Epoch 153/200\n",
      " - 5s - loss: 0.5738\n",
      "Epoch 154/200\n",
      " - 5s - loss: 0.5784\n",
      "Epoch 155/200\n",
      " - 5s - loss: 0.5873\n",
      "Epoch 156/200\n",
      " - 5s - loss: 0.5775\n",
      "Epoch 157/200\n",
      " - 5s - loss: 0.5820\n",
      "Epoch 158/200\n",
      " - 5s - loss: 0.5805\n",
      "Epoch 159/200\n",
      " - 5s - loss: 0.5939\n",
      "Epoch 160/200\n",
      " - 5s - loss: 0.5858\n",
      "Epoch 161/200\n",
      " - 5s - loss: 0.5864\n",
      "Epoch 162/200\n",
      " - 5s - loss: 0.5783\n",
      "Epoch 163/200\n",
      " - 5s - loss: 0.5821\n",
      "Epoch 164/200\n",
      " - 5s - loss: 0.5800\n",
      "Epoch 165/200\n",
      " - 5s - loss: 0.5810\n",
      "Epoch 166/200\n",
      " - 5s - loss: 0.5847\n",
      "Epoch 167/200\n",
      " - 5s - loss: 0.5757\n",
      "Epoch 168/200\n",
      " - 5s - loss: 0.5820\n",
      "Epoch 169/200\n",
      " - 5s - loss: 0.5899\n",
      "Epoch 170/200\n",
      " - 5s - loss: 0.5764\n",
      "Epoch 171/200\n",
      " - 5s - loss: 0.5807\n",
      "Epoch 172/200\n",
      " - 5s - loss: 0.5864\n",
      "Epoch 173/200\n",
      " - 5s - loss: 0.5749\n",
      "Epoch 174/200\n",
      " - 5s - loss: 0.5723\n",
      "Epoch 175/200\n",
      " - 5s - loss: 29.6194\n",
      "Epoch 176/200\n",
      " - 5s - loss: 50.6981\n",
      "Epoch 177/200\n",
      " - 5s - loss: 0.6085\n",
      "Epoch 178/200\n",
      " - 5s - loss: 0.5971\n",
      "Epoch 179/200\n",
      " - 5s - loss: 0.5841\n",
      "Epoch 180/200\n",
      " - 5s - loss: 0.5768\n",
      "Epoch 181/200\n",
      " - 5s - loss: 0.9939\n",
      "Epoch 182/200\n",
      " - 5s - loss: 0.5705\n",
      "Epoch 183/200\n",
      " - 5s - loss: 0.5665\n",
      "Epoch 184/200\n",
      " - 5s - loss: 0.5765\n",
      "Epoch 185/200\n",
      " - 5s - loss: 0.5754\n",
      "Epoch 186/200\n",
      " - 5s - loss: 0.5741\n",
      "Epoch 187/200\n",
      " - 5s - loss: 0.5759\n",
      "Epoch 188/200\n",
      " - 5s - loss: 0.5720\n",
      "Epoch 189/200\n",
      " - 5s - loss: 0.5746\n",
      "Epoch 190/200\n",
      " - 5s - loss: 0.5840\n",
      "Epoch 191/200\n",
      " - 5s - loss: 0.5756\n",
      "Epoch 192/200\n",
      " - 5s - loss: 0.5818\n",
      "Epoch 193/200\n",
      " - 5s - loss: 0.5798\n",
      "Epoch 194/200\n",
      " - 5s - loss: 0.5777\n",
      "Epoch 195/200\n",
      " - 5s - loss: 0.5705\n",
      "Epoch 196/200\n",
      " - 5s - loss: 0.5837\n",
      "Epoch 197/200\n",
      " - 5s - loss: 0.5915\n",
      "Epoch 198/200\n",
      " - 5s - loss: 0.5781\n",
      "Epoch 199/200\n",
      " - 5s - loss: 0.5739\n",
      "Epoch 200/200\n",
      " - 5s - loss: 12.7462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8c36dc828>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm_3 = Sequential()\n",
    "model_lstm_3.add(LSTM(10, input_shape=(1, train_dataset_shifted.shape[1]), activation='softplus', recurrent_activation='linear'))\n",
    "model_lstm_3.add(Dense(2))\n",
    "model_lstm_3.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model_lstm_3.fit(train_dataset, train_dataset_shifted_3, verbose=2, shuffle=False, epochs=model_epoches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set 4\n",
    "- system.load.1'\n",
    "- system.load.15'\n",
    "- system.load.5'\n",
    "- system.load.norm.1'\n",
    "- system.load.norm.15'\n",
    "- system.load.norm.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.load.1</th>\n",
       "      <th>system.load.15</th>\n",
       "      <th>system.load.5</th>\n",
       "      <th>system.load.norm.1</th>\n",
       "      <th>system.load.norm.15</th>\n",
       "      <th>system.load.norm.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.152295</td>\n",
       "      <td>-0.133203</td>\n",
       "      <td>-0.134026</td>\n",
       "      <td>-0.154622</td>\n",
       "      <td>-0.136080</td>\n",
       "      <td>-0.136533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.156706</td>\n",
       "      <td>-0.134027</td>\n",
       "      <td>-0.135839</td>\n",
       "      <td>-0.159032</td>\n",
       "      <td>-0.136740</td>\n",
       "      <td>-0.138466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.160567</td>\n",
       "      <td>-0.134851</td>\n",
       "      <td>-0.137652</td>\n",
       "      <td>-0.163002</td>\n",
       "      <td>-0.137729</td>\n",
       "      <td>-0.140158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.044208</td>\n",
       "      <td>-0.123311</td>\n",
       "      <td>-0.111068</td>\n",
       "      <td>-0.046567</td>\n",
       "      <td>-0.126188</td>\n",
       "      <td>-0.113576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.044208</td>\n",
       "      <td>-0.123311</td>\n",
       "      <td>-0.111068</td>\n",
       "      <td>-0.046567</td>\n",
       "      <td>-0.126188</td>\n",
       "      <td>-0.113576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   system.load.1  system.load.15  system.load.5  system.load.norm.1  \\\n",
       "0      -0.152295       -0.133203      -0.134026           -0.154622   \n",
       "1      -0.156706       -0.134027      -0.135839           -0.159032   \n",
       "2      -0.160567       -0.134851      -0.137652           -0.163002   \n",
       "3      -0.044208       -0.123311      -0.111068           -0.046567   \n",
       "4      -0.044208       -0.123311      -0.111068           -0.046567   \n",
       "\n",
       "   system.load.norm.15  system.load.norm.5  \n",
       "0            -0.136080           -0.136533  \n",
       "1            -0.136740           -0.138466  \n",
       "2            -0.137729           -0.140158  \n",
       "3            -0.126188           -0.113576  \n",
       "4            -0.126188           -0.113576  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_shifted_4 = train_dataset_shifted[[\n",
    "    'system.load.1',\n",
    "    'system.load.15',\n",
    "    'system.load.5',\n",
    "    'system.load.norm.1',\n",
    "    'system.load.norm.15',\n",
    "    'system.load.norm.5']]\n",
    "\n",
    "train_dataset_shifted_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 8s - loss: 162.5273\n",
      "Epoch 2/200\n",
      " - 5s - loss: 39.7505\n",
      "Epoch 3/200\n",
      " - 5s - loss: 2.3658\n",
      "Epoch 4/200\n",
      " - 5s - loss: 1.8410\n",
      "Epoch 5/200\n",
      " - 5s - loss: 1.2919\n",
      "Epoch 6/200\n",
      " - 5s - loss: 0.8720\n",
      "Epoch 7/200\n",
      " - 5s - loss: 1.6080\n",
      "Epoch 8/200\n",
      " - 5s - loss: 0.4489\n",
      "Epoch 9/200\n",
      " - 5s - loss: 0.2248\n",
      "Epoch 10/200\n",
      " - 5s - loss: 0.1920\n",
      "Epoch 11/200\n",
      " - 5s - loss: 0.1851\n",
      "Epoch 12/200\n",
      " - 5s - loss: 0.2594\n",
      "Epoch 13/200\n",
      " - 5s - loss: 0.4523\n",
      "Epoch 14/200\n",
      " - 5s - loss: 0.3518\n",
      "Epoch 15/200\n",
      " - 5s - loss: 0.1922\n",
      "Epoch 16/200\n",
      " - 5s - loss: 0.2025\n",
      "Epoch 17/200\n",
      " - 5s - loss: 0.2016\n",
      "Epoch 18/200\n",
      " - 5s - loss: 0.2152\n",
      "Epoch 19/200\n",
      " - 5s - loss: 0.2641\n",
      "Epoch 20/200\n",
      " - 5s - loss: 0.1849\n",
      "Epoch 21/200\n",
      " - 5s - loss: 0.1614\n",
      "Epoch 22/200\n",
      " - 5s - loss: 0.1816\n",
      "Epoch 23/200\n",
      " - 5s - loss: 0.1570\n",
      "Epoch 24/200\n",
      " - 5s - loss: 0.1625\n",
      "Epoch 25/200\n",
      " - 5s - loss: 0.1685\n",
      "Epoch 26/200\n",
      " - 5s - loss: 0.1771\n",
      "Epoch 27/200\n",
      " - 5s - loss: 0.1537\n",
      "Epoch 28/200\n",
      " - 5s - loss: 0.7213\n",
      "Epoch 29/200\n",
      " - 5s - loss: 0.1346\n",
      "Epoch 30/200\n",
      " - 5s - loss: 0.1370\n",
      "Epoch 31/200\n",
      " - 5s - loss: 0.1283\n",
      "Epoch 32/200\n",
      " - 5s - loss: 0.1288\n",
      "Epoch 33/200\n",
      " - 5s - loss: 0.1228\n",
      "Epoch 34/200\n",
      " - 5s - loss: 0.1195\n",
      "Epoch 35/200\n",
      " - 5s - loss: 0.1412\n",
      "Epoch 36/200\n",
      " - 5s - loss: 0.1588\n",
      "Epoch 37/200\n",
      " - 5s - loss: 0.1158\n",
      "Epoch 38/200\n",
      " - 5s - loss: 0.1074\n",
      "Epoch 39/200\n",
      " - 5s - loss: 0.1062\n",
      "Epoch 40/200\n",
      " - 5s - loss: 0.1317\n",
      "Epoch 41/200\n",
      " - 5s - loss: 0.1152\n",
      "Epoch 42/200\n",
      " - 5s - loss: 0.1052\n",
      "Epoch 43/200\n",
      " - 5s - loss: 0.1023\n",
      "Epoch 44/200\n",
      " - 5s - loss: 0.0995\n",
      "Epoch 45/200\n",
      " - 5s - loss: 0.1016\n",
      "Epoch 46/200\n",
      " - 5s - loss: 0.1173\n",
      "Epoch 47/200\n",
      " - 5s - loss: 0.1194\n",
      "Epoch 48/200\n",
      " - 5s - loss: 0.1039\n",
      "Epoch 49/200\n",
      " - 5s - loss: 0.0976\n",
      "Epoch 50/200\n",
      " - 5s - loss: 0.1120\n",
      "Epoch 51/200\n",
      " - 5s - loss: 0.1028\n",
      "Epoch 52/200\n",
      " - 5s - loss: 0.0902\n",
      "Epoch 53/200\n",
      " - 5s - loss: 0.0937\n",
      "Epoch 54/200\n",
      " - 5s - loss: 0.1126\n",
      "Epoch 55/200\n",
      " - 5s - loss: 0.0956\n",
      "Epoch 56/200\n",
      " - 5s - loss: 0.0861\n",
      "Epoch 57/200\n",
      " - 5s - loss: 0.0924\n",
      "Epoch 58/200\n",
      " - 5s - loss: 4.6706\n",
      "Epoch 59/200\n",
      " - 5s - loss: 0.1351\n",
      "Epoch 60/200\n",
      " - 5s - loss: 0.0862\n",
      "Epoch 61/200\n",
      " - 5s - loss: 0.0830\n",
      "Epoch 62/200\n",
      " - 5s - loss: 0.0884\n",
      "Epoch 63/200\n",
      " - 5s - loss: 0.0757\n",
      "Epoch 64/200\n",
      " - 5s - loss: 0.0818\n",
      "Epoch 65/200\n",
      " - 5s - loss: 0.1537\n",
      "Epoch 66/200\n",
      " - 5s - loss: 0.1121\n",
      "Epoch 67/200\n",
      " - 5s - loss: 0.0871\n",
      "Epoch 68/200\n",
      " - 5s - loss: 0.0839\n",
      "Epoch 69/200\n",
      " - 5s - loss: 0.0888\n",
      "Epoch 70/200\n",
      " - 5s - loss: 0.0951\n",
      "Epoch 71/200\n",
      " - 5s - loss: 0.0832\n",
      "Epoch 72/200\n",
      " - 5s - loss: 0.0752\n",
      "Epoch 73/200\n",
      " - 5s - loss: 0.1241\n",
      "Epoch 74/200\n",
      " - 5s - loss: 0.0808\n",
      "Epoch 75/200\n",
      " - 5s - loss: 0.0851\n",
      "Epoch 76/200\n",
      " - 5s - loss: 0.0873\n",
      "Epoch 77/200\n",
      " - 5s - loss: 0.0844\n",
      "Epoch 78/200\n",
      " - 5s - loss: 0.1123\n",
      "Epoch 79/200\n",
      " - 5s - loss: 0.0813\n",
      "Epoch 80/200\n",
      " - 5s - loss: 0.0733\n",
      "Epoch 81/200\n",
      " - 5s - loss: 0.0695\n",
      "Epoch 82/200\n",
      " - 5s - loss: 0.1585\n",
      "Epoch 83/200\n",
      " - 5s - loss: 0.0818\n",
      "Epoch 84/200\n",
      " - 5s - loss: 0.0798\n",
      "Epoch 85/200\n",
      " - 5s - loss: 0.0727\n",
      "Epoch 86/200\n",
      " - 5s - loss: 0.1180\n",
      "Epoch 87/200\n",
      " - 5s - loss: 0.0729\n",
      "Epoch 88/200\n",
      " - 5s - loss: 0.0893\n",
      "Epoch 89/200\n",
      " - 5s - loss: 0.0810\n",
      "Epoch 90/200\n",
      " - 5s - loss: 0.0765\n",
      "Epoch 91/200\n",
      " - 5s - loss: 0.1071\n",
      "Epoch 92/200\n",
      " - 5s - loss: 0.0794\n",
      "Epoch 93/200\n",
      " - 5s - loss: 0.0673\n",
      "Epoch 94/200\n",
      " - 5s - loss: 0.0750\n",
      "Epoch 95/200\n",
      " - 5s - loss: 0.0814\n",
      "Epoch 96/200\n",
      " - 5s - loss: 0.1701\n",
      "Epoch 97/200\n",
      " - 5s - loss: 0.0923\n",
      "Epoch 98/200\n",
      " - 5s - loss: 0.0613\n",
      "Epoch 99/200\n",
      " - 5s - loss: 0.0808\n",
      "Epoch 100/200\n",
      " - 5s - loss: 0.0898\n",
      "Epoch 101/200\n",
      " - 5s - loss: 0.1099\n",
      "Epoch 102/200\n",
      " - 5s - loss: 0.0696\n",
      "Epoch 103/200\n",
      " - 5s - loss: 0.0764\n",
      "Epoch 104/200\n",
      " - 5s - loss: 0.0771\n",
      "Epoch 105/200\n",
      " - 5s - loss: 0.1189\n",
      "Epoch 106/200\n",
      " - 5s - loss: 0.0763\n",
      "Epoch 107/200\n",
      " - 5s - loss: 0.0704\n",
      "Epoch 108/200\n",
      " - 5s - loss: 0.0821\n",
      "Epoch 109/200\n",
      " - 5s - loss: 0.0810\n",
      "Epoch 110/200\n",
      " - 5s - loss: 0.0988\n",
      "Epoch 111/200\n",
      " - 5s - loss: 0.0730\n",
      "Epoch 112/200\n",
      " - 5s - loss: 0.0625\n",
      "Epoch 113/200\n",
      " - 5s - loss: 0.0589\n",
      "Epoch 114/200\n",
      " - 5s - loss: 0.0997\n",
      "Epoch 115/200\n",
      " - 5s - loss: 0.0919\n",
      "Epoch 116/200\n",
      " - 5s - loss: 0.0920\n",
      "Epoch 117/200\n",
      " - 5s - loss: 0.1087\n",
      "Epoch 118/200\n",
      " - 5s - loss: 0.0670\n",
      "Epoch 119/200\n",
      " - 5s - loss: 0.0675\n",
      "Epoch 120/200\n",
      " - 5s - loss: 7.5132\n",
      "Epoch 121/200\n",
      " - 5s - loss: 0.0922\n",
      "Epoch 122/200\n",
      " - 5s - loss: 0.0908\n",
      "Epoch 123/200\n",
      " - 5s - loss: 0.0788\n",
      "Epoch 124/200\n",
      " - 5s - loss: 0.0935\n",
      "Epoch 125/200\n",
      " - 5s - loss: 0.0881\n",
      "Epoch 126/200\n",
      " - 5s - loss: 0.0905\n",
      "Epoch 127/200\n",
      " - 5s - loss: 0.0711\n",
      "Epoch 128/200\n",
      " - 5s - loss: 0.0757\n",
      "Epoch 129/200\n",
      " - 5s - loss: 0.1279\n",
      "Epoch 130/200\n",
      " - 5s - loss: 0.0680\n",
      "Epoch 131/200\n",
      " - 5s - loss: 0.0737\n",
      "Epoch 132/200\n",
      " - 5s - loss: 0.0890\n",
      "Epoch 133/200\n",
      " - 5s - loss: 0.0649\n",
      "Epoch 134/200\n",
      " - 5s - loss: 0.0859\n",
      "Epoch 135/200\n",
      " - 5s - loss: 0.0990\n",
      "Epoch 136/200\n",
      " - 5s - loss: 0.0716\n",
      "Epoch 137/200\n",
      " - 5s - loss: 0.0651\n",
      "Epoch 138/200\n",
      " - 5s - loss: 0.1139\n",
      "Epoch 139/200\n",
      " - 5s - loss: 0.0709\n",
      "Epoch 140/200\n",
      " - 5s - loss: 0.0781\n",
      "Epoch 141/200\n",
      " - 5s - loss: 0.0779\n",
      "Epoch 142/200\n",
      " - 5s - loss: 0.3444\n",
      "Epoch 143/200\n",
      " - 5s - loss: 0.0629\n",
      "Epoch 144/200\n",
      " - 5s - loss: 0.0632\n",
      "Epoch 145/200\n",
      " - 5s - loss: 0.0941\n",
      "Epoch 146/200\n",
      " - 5s - loss: 0.1015\n",
      "Epoch 147/200\n",
      " - 5s - loss: 0.0601\n",
      "Epoch 148/200\n",
      " - 5s - loss: 0.0865\n",
      "Epoch 149/200\n",
      " - 5s - loss: 0.0709\n",
      "Epoch 150/200\n",
      " - 5s - loss: 0.0800\n",
      "Epoch 151/200\n",
      " - 5s - loss: 0.0888\n",
      "Epoch 152/200\n",
      " - 5s - loss: 0.0618\n",
      "Epoch 153/200\n",
      " - 5s - loss: 0.0743\n",
      "Epoch 154/200\n",
      " - 5s - loss: 0.1150\n",
      "Epoch 155/200\n",
      " - 5s - loss: 0.0702\n",
      "Epoch 156/200\n",
      " - 5s - loss: 0.0732\n",
      "Epoch 157/200\n",
      " - 5s - loss: 0.1057\n",
      "Epoch 158/200\n",
      " - 5s - loss: 0.0664\n",
      "Epoch 159/200\n",
      " - 5s - loss: 0.0641\n",
      "Epoch 160/200\n",
      " - 5s - loss: 0.0977\n",
      "Epoch 161/200\n",
      " - 5s - loss: 0.0790\n",
      "Epoch 162/200\n",
      " - 5s - loss: 0.0743\n",
      "Epoch 163/200\n",
      " - 5s - loss: 1.7846\n",
      "Epoch 164/200\n",
      " - 5s - loss: 0.0639\n",
      "Epoch 165/200\n",
      " - 5s - loss: 0.0828\n",
      "Epoch 166/200\n",
      " - 5s - loss: 0.0758\n",
      "Epoch 167/200\n",
      " - 5s - loss: 0.0823\n",
      "Epoch 168/200\n",
      " - 5s - loss: 0.0642\n",
      "Epoch 169/200\n",
      " - 5s - loss: 0.0827\n",
      "Epoch 170/200\n",
      " - 5s - loss: 0.0958\n",
      "Epoch 171/200\n",
      " - 5s - loss: 0.0678\n",
      "Epoch 172/200\n",
      " - 5s - loss: 0.0738\n",
      "Epoch 173/200\n",
      " - 5s - loss: 0.0884\n",
      "Epoch 174/200\n",
      " - 5s - loss: 0.0623\n",
      "Epoch 175/200\n",
      " - 5s - loss: 0.0753\n",
      "Epoch 176/200\n",
      " - 5s - loss: 0.0922\n",
      "Epoch 177/200\n",
      " - 5s - loss: 0.0608\n",
      "Epoch 178/200\n",
      " - 5s - loss: 0.0777\n",
      "Epoch 179/200\n",
      " - 5s - loss: 0.1017\n",
      "Epoch 180/200\n",
      " - 5s - loss: 0.0702\n",
      "Epoch 181/200\n",
      " - 5s - loss: 0.1141\n",
      "Epoch 182/200\n",
      " - 5s - loss: 0.0922\n",
      "Epoch 183/200\n",
      " - 5s - loss: 0.0613\n",
      "Epoch 184/200\n",
      " - 5s - loss: 0.0729\n",
      "Epoch 185/200\n",
      " - 5s - loss: 0.0921\n",
      "Epoch 186/200\n",
      " - 5s - loss: 0.0687\n",
      "Epoch 187/200\n",
      " - 5s - loss: 0.0733\n",
      "Epoch 188/200\n",
      " - 5s - loss: 0.1116\n",
      "Epoch 189/200\n",
      " - 5s - loss: 0.0600\n",
      "Epoch 190/200\n",
      " - 5s - loss: 0.0617\n",
      "Epoch 191/200\n",
      " - 5s - loss: 0.0960\n",
      "Epoch 192/200\n",
      " - 5s - loss: 0.0663\n",
      "Epoch 193/200\n",
      " - 5s - loss: 0.0703\n",
      "Epoch 194/200\n",
      " - 5s - loss: 0.0982\n",
      "Epoch 195/200\n",
      " - 5s - loss: 0.0783\n",
      "Epoch 196/200\n",
      " - 5s - loss: 0.0808\n",
      "Epoch 197/200\n",
      " - 5s - loss: 0.1498\n",
      "Epoch 198/200\n",
      " - 5s - loss: 0.0569\n",
      "Epoch 199/200\n",
      " - 5s - loss: 0.0614\n",
      "Epoch 200/200\n",
      " - 6s - loss: 0.1003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8bf797c18>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm_4 = Sequential()\n",
    "model_lstm_4.add(LSTM(10, input_shape=(1, train_dataset_shifted.shape[1]), activation='softplus', recurrent_activation='linear'))\n",
    "model_lstm_4.add(Dense(6))\n",
    "model_lstm_4.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model_lstm_4.fit(train_dataset, train_dataset_shifted_4, verbose=2, shuffle=False, epochs=model_epoches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set 5\n",
    "- system.cpu.idle.pct'\n",
    "- system.cpu.softirq.pct'\n",
    "- system.cpu.system.pct'\n",
    "- jolokia.metrics.memory.heap_memory_usage.used'\n",
    "- jolokia.metrics.memory.non_heap_memory_usage.used'\n",
    "- jolokia.metrics.threading.daemon_thread_count'\n",
    "- jolokia.metrics.threading.thread_count'\n",
    "- system.memory.actual.used.pct'\n",
    "- system.memory.swap.used.pct'\n",
    "- system.memory.used.pct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu.idle.pct</th>\n",
       "      <th>system.cpu.softirq.pct</th>\n",
       "      <th>system.cpu.system.pct</th>\n",
       "      <th>jolokia.metrics.memory.heap_memory_usage.used</th>\n",
       "      <th>jolokia.metrics.memory.non_heap_memory_usage.used</th>\n",
       "      <th>jolokia.metrics.threading.daemon_thread_count</th>\n",
       "      <th>jolokia.metrics.threading.thread_count</th>\n",
       "      <th>system.memory.actual.used.pct</th>\n",
       "      <th>system.memory.swap.used.pct</th>\n",
       "      <th>system.memory.used.pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.279101</td>\n",
       "      <td>-0.378447</td>\n",
       "      <td>-0.133873</td>\n",
       "      <td>-1.005035</td>\n",
       "      <td>-1.670330</td>\n",
       "      <td>-0.459191</td>\n",
       "      <td>-1.10143</td>\n",
       "      <td>-1.037900</td>\n",
       "      <td>-0.078425</td>\n",
       "      <td>0.334706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.246603</td>\n",
       "      <td>0.141898</td>\n",
       "      <td>0.795873</td>\n",
       "      <td>-0.204441</td>\n",
       "      <td>-1.669447</td>\n",
       "      <td>-0.459191</td>\n",
       "      <td>-1.10143</td>\n",
       "      <td>-1.033430</td>\n",
       "      <td>-0.078425</td>\n",
       "      <td>0.386437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067553</td>\n",
       "      <td>0.364903</td>\n",
       "      <td>-0.392135</td>\n",
       "      <td>-0.204441</td>\n",
       "      <td>-1.669447</td>\n",
       "      <td>-0.459191</td>\n",
       "      <td>-1.10143</td>\n",
       "      <td>-1.042371</td>\n",
       "      <td>-0.078425</td>\n",
       "      <td>0.386437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.198013</td>\n",
       "      <td>-0.155442</td>\n",
       "      <td>0.709786</td>\n",
       "      <td>-0.204441</td>\n",
       "      <td>-1.669447</td>\n",
       "      <td>-0.459191</td>\n",
       "      <td>-1.10143</td>\n",
       "      <td>-1.037900</td>\n",
       "      <td>-0.078425</td>\n",
       "      <td>0.438169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.212231</td>\n",
       "      <td>-0.254556</td>\n",
       "      <td>-0.047785</td>\n",
       "      <td>-0.204441</td>\n",
       "      <td>-1.669447</td>\n",
       "      <td>-0.459191</td>\n",
       "      <td>-1.10143</td>\n",
       "      <td>-1.028959</td>\n",
       "      <td>-0.078425</td>\n",
       "      <td>0.467729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   system.cpu.idle.pct  system.cpu.softirq.pct  system.cpu.system.pct  \\\n",
       "0             0.279101               -0.378447              -0.133873   \n",
       "1             0.246603                0.141898               0.795873   \n",
       "2             0.067553                0.364903              -0.392135   \n",
       "3             0.198013               -0.155442               0.709786   \n",
       "4             0.212231               -0.254556              -0.047785   \n",
       "\n",
       "   jolokia.metrics.memory.heap_memory_usage.used  \\\n",
       "0                                      -1.005035   \n",
       "1                                      -0.204441   \n",
       "2                                      -0.204441   \n",
       "3                                      -0.204441   \n",
       "4                                      -0.204441   \n",
       "\n",
       "   jolokia.metrics.memory.non_heap_memory_usage.used  \\\n",
       "0                                          -1.670330   \n",
       "1                                          -1.669447   \n",
       "2                                          -1.669447   \n",
       "3                                          -1.669447   \n",
       "4                                          -1.669447   \n",
       "\n",
       "   jolokia.metrics.threading.daemon_thread_count  \\\n",
       "0                                      -0.459191   \n",
       "1                                      -0.459191   \n",
       "2                                      -0.459191   \n",
       "3                                      -0.459191   \n",
       "4                                      -0.459191   \n",
       "\n",
       "   jolokia.metrics.threading.thread_count  system.memory.actual.used.pct  \\\n",
       "0                                -1.10143                      -1.037900   \n",
       "1                                -1.10143                      -1.033430   \n",
       "2                                -1.10143                      -1.042371   \n",
       "3                                -1.10143                      -1.037900   \n",
       "4                                -1.10143                      -1.028959   \n",
       "\n",
       "   system.memory.swap.used.pct  system.memory.used.pct  \n",
       "0                    -0.078425                0.334706  \n",
       "1                    -0.078425                0.386437  \n",
       "2                    -0.078425                0.386437  \n",
       "3                    -0.078425                0.438169  \n",
       "4                    -0.078425                0.467729  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_shifted_5 = train_dataset_shifted[[\n",
    "    'system.cpu.idle.pct',\n",
    "    'system.cpu.softirq.pct',\n",
    "    'system.cpu.system.pct',\n",
    "    'jolokia.metrics.memory.heap_memory_usage.used',\n",
    "    'jolokia.metrics.memory.non_heap_memory_usage.used',\n",
    "    'jolokia.metrics.threading.daemon_thread_count',\n",
    "    'jolokia.metrics.threading.thread_count',\n",
    "    'system.memory.actual.used.pct',\n",
    "    'system.memory.swap.used.pct',\n",
    "    'system.memory.used.pct']]\n",
    "\n",
    "train_dataset_shifted_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 9s - loss: 539.2354\n",
      "Epoch 2/200\n",
      " - 5s - loss: 10.2317\n",
      "Epoch 3/200\n",
      " - 5s - loss: 4.8082\n",
      "Epoch 4/200\n",
      " - 5s - loss: 5.9810\n",
      "Epoch 5/200\n",
      " - 5s - loss: 4.9344\n",
      "Epoch 6/200\n",
      " - 5s - loss: 2.3154\n",
      "Epoch 7/200\n",
      " - 5s - loss: 1.3939\n",
      "Epoch 8/200\n",
      " - 5s - loss: 0.8941\n",
      "Epoch 9/200\n",
      " - 5s - loss: 0.7023\n",
      "Epoch 10/200\n",
      " - 5s - loss: 0.5849\n",
      "Epoch 11/200\n",
      " - 5s - loss: 0.5426\n",
      "Epoch 12/200\n",
      " - 5s - loss: 0.5346\n",
      "Epoch 13/200\n",
      " - 5s - loss: 0.5524\n",
      "Epoch 14/200\n",
      " - 5s - loss: 0.5264\n",
      "Epoch 15/200\n",
      " - 5s - loss: 0.5081\n",
      "Epoch 16/200\n",
      " - 5s - loss: 0.4877\n",
      "Epoch 17/200\n",
      " - 5s - loss: 0.4808\n",
      "Epoch 18/200\n",
      " - 5s - loss: 0.4801\n",
      "Epoch 19/200\n",
      " - 5s - loss: 0.4763\n",
      "Epoch 20/200\n",
      " - 5s - loss: 0.4652\n",
      "Epoch 21/200\n",
      " - 5s - loss: 0.4632\n",
      "Epoch 22/200\n",
      " - 5s - loss: 0.4666\n",
      "Epoch 23/200\n",
      " - 5s - loss: 0.4560\n",
      "Epoch 24/200\n",
      " - 5s - loss: 0.4580\n",
      "Epoch 25/200\n",
      " - 5s - loss: 0.4502\n",
      "Epoch 26/200\n",
      " - 5s - loss: 0.4535\n",
      "Epoch 27/200\n",
      " - 5s - loss: 0.4494\n",
      "Epoch 28/200\n",
      " - 5s - loss: 0.4561\n",
      "Epoch 29/200\n",
      " - 5s - loss: 0.4444\n",
      "Epoch 30/200\n",
      " - 5s - loss: 0.4398\n",
      "Epoch 31/200\n",
      " - 5s - loss: 0.4409\n",
      "Epoch 32/200\n",
      " - 5s - loss: 0.4355\n",
      "Epoch 33/200\n",
      " - 5s - loss: 0.4376\n",
      "Epoch 34/200\n",
      " - 5s - loss: 0.4313\n",
      "Epoch 35/200\n",
      " - 5s - loss: 0.4402\n",
      "Epoch 36/200\n",
      " - 5s - loss: 0.4319\n",
      "Epoch 37/200\n",
      " - 5s - loss: 0.4322\n",
      "Epoch 38/200\n",
      " - 5s - loss: 0.4349\n",
      "Epoch 39/200\n",
      " - 5s - loss: 0.4336\n",
      "Epoch 40/200\n",
      " - 5s - loss: 0.4437\n",
      "Epoch 41/200\n",
      " - 5s - loss: 0.4457\n",
      "Epoch 42/200\n",
      " - 5s - loss: 0.5379\n",
      "Epoch 43/200\n",
      " - 5s - loss: 0.4324\n",
      "Epoch 44/200\n",
      " - 5s - loss: 0.4333\n",
      "Epoch 45/200\n",
      " - 5s - loss: 0.4370\n",
      "Epoch 46/200\n",
      " - 5s - loss: 0.4364\n",
      "Epoch 47/200\n",
      " - 5s - loss: 0.4272\n",
      "Epoch 48/200\n",
      " - 5s - loss: 0.4290\n",
      "Epoch 49/200\n",
      " - 5s - loss: 0.4310\n",
      "Epoch 50/200\n",
      " - 5s - loss: 0.4259\n",
      "Epoch 51/200\n",
      " - 5s - loss: 0.4334\n",
      "Epoch 52/200\n",
      " - 5s - loss: 0.4252\n",
      "Epoch 53/200\n",
      " - 5s - loss: 0.4283\n",
      "Epoch 54/200\n",
      " - 5s - loss: 0.4264\n",
      "Epoch 55/200\n",
      " - 5s - loss: 0.4335\n",
      "Epoch 56/200\n",
      " - 5s - loss: 0.4289\n",
      "Epoch 57/200\n",
      " - 5s - loss: 0.4203\n",
      "Epoch 58/200\n",
      " - 5s - loss: 0.4196\n",
      "Epoch 59/200\n",
      " - 5s - loss: 0.5279\n",
      "Epoch 60/200\n",
      " - 5s - loss: 0.4233\n",
      "Epoch 61/200\n",
      " - 5s - loss: 0.4294\n",
      "Epoch 62/200\n",
      " - 5s - loss: 0.5839\n",
      "Epoch 63/200\n",
      " - 5s - loss: 0.4182\n",
      "Epoch 64/200\n",
      " - 5s - loss: 0.4205\n",
      "Epoch 65/200\n",
      " - 5s - loss: 0.4197\n",
      "Epoch 66/200\n",
      " - 5s - loss: 0.4280\n",
      "Epoch 67/200\n",
      " - 5s - loss: 0.4161\n",
      "Epoch 68/200\n",
      " - 5s - loss: 0.4175\n",
      "Epoch 69/200\n",
      " - 5s - loss: 0.4204\n",
      "Epoch 70/200\n",
      " - 5s - loss: 0.4195\n",
      "Epoch 71/200\n",
      " - 5s - loss: 0.4240\n",
      "Epoch 72/200\n",
      " - 5s - loss: 0.4174\n",
      "Epoch 73/200\n",
      " - 5s - loss: 0.4144\n",
      "Epoch 74/200\n",
      " - 5s - loss: 0.4201\n",
      "Epoch 75/200\n",
      " - 5s - loss: 0.4141\n",
      "Epoch 76/200\n",
      " - 5s - loss: 0.4211\n",
      "Epoch 77/200\n",
      " - 5s - loss: 0.4158\n",
      "Epoch 78/200\n",
      " - 5s - loss: 0.4172\n",
      "Epoch 79/200\n",
      " - 5s - loss: 0.4198\n",
      "Epoch 80/200\n",
      " - 5s - loss: 0.4271\n",
      "Epoch 81/200\n",
      " - 5s - loss: 0.4121\n",
      "Epoch 82/200\n",
      " - 5s - loss: 0.4113\n",
      "Epoch 83/200\n",
      " - 5s - loss: 0.4113\n",
      "Epoch 84/200\n",
      " - 5s - loss: 0.4116\n",
      "Epoch 85/200\n",
      " - 5s - loss: 0.4169\n",
      "Epoch 86/200\n",
      " - 5s - loss: 0.4131\n",
      "Epoch 87/200\n",
      " - 5s - loss: 0.4097\n",
      "Epoch 88/200\n",
      " - 5s - loss: 0.4174\n",
      "Epoch 89/200\n",
      " - 5s - loss: 0.4208\n",
      "Epoch 90/200\n",
      " - 5s - loss: 0.4091\n",
      "Epoch 91/200\n",
      " - 5s - loss: 0.4087\n",
      "Epoch 92/200\n",
      " - 5s - loss: 0.4122\n",
      "Epoch 93/200\n",
      " - 5s - loss: 0.4097\n",
      "Epoch 94/200\n",
      " - 5s - loss: 0.4101\n",
      "Epoch 95/200\n",
      " - 5s - loss: 0.4140\n",
      "Epoch 96/200\n",
      " - 5s - loss: 0.4091\n",
      "Epoch 97/200\n",
      " - 5s - loss: 0.4141\n",
      "Epoch 98/200\n",
      " - 5s - loss: 0.4108\n",
      "Epoch 99/200\n",
      " - 5s - loss: 0.4141\n",
      "Epoch 100/200\n",
      " - 5s - loss: 0.4081\n",
      "Epoch 101/200\n",
      " - 5s - loss: 0.4140\n",
      "Epoch 102/200\n",
      " - 5s - loss: 0.4108\n",
      "Epoch 103/200\n",
      " - 5s - loss: 0.4141\n",
      "Epoch 104/200\n",
      " - 5s - loss: 1.0843\n",
      "Epoch 105/200\n",
      " - 5s - loss: 0.4092\n",
      "Epoch 106/200\n",
      " - 5s - loss: 0.4088\n",
      "Epoch 107/200\n",
      " - 5s - loss: 0.4075\n",
      "Epoch 108/200\n",
      " - 5s - loss: 0.4150\n",
      "Epoch 109/200\n",
      " - 5s - loss: 0.4047\n",
      "Epoch 110/200\n",
      " - 5s - loss: 0.4073\n",
      "Epoch 111/200\n",
      " - 5s - loss: 0.4082\n",
      "Epoch 112/200\n",
      " - 5s - loss: 0.4119\n",
      "Epoch 113/200\n",
      " - 5s - loss: 0.4185\n",
      "Epoch 114/200\n",
      " - 5s - loss: 0.4083\n",
      "Epoch 115/200\n",
      " - 5s - loss: 0.4041\n",
      "Epoch 116/200\n",
      " - 5s - loss: 0.4091\n",
      "Epoch 117/200\n",
      " - 5s - loss: 0.4041\n",
      "Epoch 118/200\n",
      " - 5s - loss: 0.4136\n",
      "Epoch 119/200\n",
      " - 5s - loss: 0.4024\n",
      "Epoch 120/200\n",
      " - 5s - loss: 0.4049\n",
      "Epoch 121/200\n",
      " - 5s - loss: 0.4066\n",
      "Epoch 122/200\n",
      " - 5s - loss: 0.4061\n",
      "Epoch 123/200\n",
      " - 5s - loss: 0.4166\n",
      "Epoch 124/200\n",
      " - 5s - loss: 0.4069\n",
      "Epoch 125/200\n",
      " - 5s - loss: 0.4088\n",
      "Epoch 126/200\n",
      " - 5s - loss: 0.4054\n",
      "Epoch 127/200\n",
      " - 5s - loss: 0.4062\n",
      "Epoch 128/200\n",
      " - 5s - loss: 0.4103\n",
      "Epoch 129/200\n",
      " - 5s - loss: 0.4051\n",
      "Epoch 130/200\n",
      " - 5s - loss: 0.4087\n",
      "Epoch 131/200\n",
      " - 5s - loss: 0.4052\n",
      "Epoch 132/200\n",
      " - 5s - loss: 0.4119\n",
      "Epoch 133/200\n",
      " - 5s - loss: 0.4066\n",
      "Epoch 134/200\n",
      " - 5s - loss: 0.4058\n",
      "Epoch 135/200\n",
      " - 5s - loss: 0.4035\n",
      "Epoch 136/200\n",
      " - 5s - loss: 0.4095\n",
      "Epoch 137/200\n",
      " - 5s - loss: 0.5443\n",
      "Epoch 138/200\n",
      " - 5s - loss: 0.4648\n",
      "Epoch 139/200\n",
      " - 5s - loss: 0.4012\n",
      "Epoch 140/200\n",
      " - 5s - loss: 0.4039\n",
      "Epoch 141/200\n",
      " - 5s - loss: 0.4056\n",
      "Epoch 142/200\n",
      " - 5s - loss: 0.4127\n",
      "Epoch 143/200\n",
      " - 5s - loss: 0.4014\n",
      "Epoch 144/200\n",
      " - 5s - loss: 0.4007\n",
      "Epoch 145/200\n",
      " - 5s - loss: 0.4009\n",
      "Epoch 146/200\n",
      " - 5s - loss: 0.4124\n",
      "Epoch 147/200\n",
      " - 5s - loss: 0.4123\n",
      "Epoch 148/200\n",
      " - 5s - loss: 0.4042\n",
      "Epoch 149/200\n",
      " - 5s - loss: 0.3998\n",
      "Epoch 150/200\n",
      " - 5s - loss: 0.4050\n",
      "Epoch 151/200\n",
      " - 5s - loss: 0.4067\n",
      "Epoch 152/200\n",
      " - 5s - loss: 0.4137\n",
      "Epoch 153/200\n",
      " - 5s - loss: 0.4020\n",
      "Epoch 154/200\n",
      " - 5s - loss: 0.7520\n",
      "Epoch 155/200\n",
      " - 5s - loss: 0.4021\n",
      "Epoch 156/200\n",
      " - 5s - loss: 0.4047\n",
      "Epoch 157/200\n",
      " - 5s - loss: 0.4075\n",
      "Epoch 158/200\n",
      " - 5s - loss: 1.9505\n",
      "Epoch 159/200\n",
      " - 5s - loss: 0.4054\n",
      "Epoch 160/200\n",
      " - 5s - loss: 0.4057\n",
      "Epoch 161/200\n",
      " - 5s - loss: 0.4080\n",
      "Epoch 162/200\n",
      " - 5s - loss: 0.4125\n",
      "Epoch 163/200\n",
      " - 5s - loss: 0.3971\n",
      "Epoch 164/200\n",
      " - 5s - loss: 0.4041\n",
      "Epoch 165/200\n",
      " - 5s - loss: 0.3982\n",
      "Epoch 166/200\n",
      " - 5s - loss: 0.4023\n",
      "Epoch 167/200\n",
      " - 5s - loss: 0.4003\n",
      "Epoch 168/200\n",
      " - 5s - loss: 0.4100\n",
      "Epoch 169/200\n",
      " - 5s - loss: 0.4108\n",
      "Epoch 170/200\n",
      " - 5s - loss: 0.4107\n",
      "Epoch 171/200\n",
      " - 5s - loss: 0.3980\n",
      "Epoch 172/200\n",
      " - 5s - loss: 0.4034\n",
      "Epoch 173/200\n",
      " - 5s - loss: 0.4075\n",
      "Epoch 174/200\n",
      " - 5s - loss: 0.4090\n",
      "Epoch 175/200\n",
      " - 5s - loss: 0.4004\n",
      "Epoch 176/200\n",
      " - 5s - loss: 0.4035\n",
      "Epoch 177/200\n",
      " - 5s - loss: 0.4020\n",
      "Epoch 178/200\n",
      " - 5s - loss: 0.4065\n",
      "Epoch 179/200\n",
      " - 5s - loss: 0.4073\n",
      "Epoch 180/200\n",
      " - 5s - loss: 7.3622\n",
      "Epoch 181/200\n",
      " - 5s - loss: 0.3981\n",
      "Epoch 182/200\n",
      " - 5s - loss: 0.4052\n",
      "Epoch 183/200\n",
      " - 5s - loss: 0.4034\n",
      "Epoch 184/200\n",
      " - 6s - loss: 0.4086\n",
      "Epoch 185/200\n",
      " - 5s - loss: 0.4004\n",
      "Epoch 186/200\n",
      " - 5s - loss: 0.4015\n",
      "Epoch 187/200\n",
      " - 5s - loss: 0.3994\n",
      "Epoch 188/200\n",
      " - 5s - loss: 0.4039\n",
      "Epoch 189/200\n",
      " - 5s - loss: 0.4066\n",
      "Epoch 190/200\n",
      " - 5s - loss: 0.3982\n",
      "Epoch 191/200\n",
      " - 5s - loss: 0.3956\n",
      "Epoch 192/200\n",
      " - 5s - loss: 0.4049\n",
      "Epoch 193/200\n",
      " - 5s - loss: 0.4038\n",
      "Epoch 194/200\n",
      " - 5s - loss: 0.4107\n",
      "Epoch 195/200\n",
      " - 5s - loss: 0.3996\n",
      "Epoch 196/200\n",
      " - 5s - loss: 0.4001\n",
      "Epoch 197/200\n",
      " - 5s - loss: 0.4018\n",
      "Epoch 198/200\n",
      " - 5s - loss: 0.4038\n",
      "Epoch 199/200\n",
      " - 5s - loss: 0.4050\n",
      "Epoch 200/200\n",
      " - 5s - loss: 0.3967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8bef71f28>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm_5 = Sequential()\n",
    "model_lstm_5.add(LSTM(10, input_shape=(1, train_dataset_shifted.shape[1]), activation='softplus', recurrent_activation='linear'))\n",
    "model_lstm_5.add(Dense(10))\n",
    "model_lstm_5.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model_lstm_5.fit(train_dataset, train_dataset_shifted_5, verbose=2, shuffle=False, epochs=model_epoches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved models to disk\n"
     ]
    }
   ],
   "source": [
    "directory = \"shift-\"+str(shift)\n",
    "models = [model_lstm_1, model_lstm_2, model_lstm_3, model_lstm_4, model_lstm_5]\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "count = 0\n",
    "for model_to_save in models:\n",
    "    count += 1\n",
    "    model_json = model_to_save.to_json()\n",
    "    with open(directory+\"/model_lstm_\"+str(count)+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "        # serialize weights to HDF5\n",
    "    model_to_save.save_weights(directory+\"/model_lstm_\"+str(count)+\".h5\")\n",
    "\n",
    "print(\"Saved models to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
